{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook was used to perform training and evaluation of a simple two-hidden-layer and three-hidden layers on\n",
    "MNIST and Fashion MNIST datasets.\n",
    "\n",
    "No external dependencies are needed, simply open the notebook in Jupyter server and run all cells. Note that the simulation\n",
    "is relatively long (each model took approx. 30 - 60 minutes on one dataset) and thus strong GPU or cloud computation\n",
    "is recommended.\n",
    "\n",
    "Part of the code used is adapted from the SpyTorch GitHub repository: https://github.com/fzenke/spytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seed for consistent behavior (though different results will still occur due to computation on GPU - if present)\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set the device for computation\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set data type for computations in the neural network\n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Function to convert the inputs into spikes\n",
    "def convert_to_firing_time(x, tau=20, thr=0.2, tmax=1.0, epsilon=1e-7):\n",
    "    idx = x < thr\n",
    "    x = np.clip(x, thr + epsilon, 1e9)\n",
    "    T = tau * np.log(x / (x - thr))\n",
    "    T[idx] = tmax\n",
    "    return T\n",
    "\n",
    "# This function is used to generate features and labels for the simulator in batches\n",
    "def sparse_data_generator(x, y, batch_size, num_steps, num_units, time_step=1e-3, shuffle=True):\n",
    "\n",
    "    labels_ = np.array(y, dtype=np.int)\n",
    "    number_of_batches = len(x) // batch_size\n",
    "    sample_index = np.arange(len(x))\n",
    "\n",
    "    # compute discrete firing times\n",
    "    tau_eff = 20e-3 / time_step\n",
    "    firing_times = np.array(convert_to_firing_time(x, tau=tau_eff, tmax=num_steps), dtype=np.int)\n",
    "    unit_numbers = np.arange(num_units)\n",
    "\n",
    "    # shuffle if set to True\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "\n",
    "    counter = 0\n",
    "    while counter < number_of_batches:\n",
    "        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n",
    "\n",
    "        coo = [[] for _ in range(3)]\n",
    "        for bc, idx in enumerate(batch_index):\n",
    "            c = firing_times[idx] < num_steps\n",
    "            times, units = firing_times[idx][c], unit_numbers[c]\n",
    "\n",
    "            batch = [bc for _ in range(len(times))]\n",
    "            coo[0].extend(batch)\n",
    "            coo[1].extend(times)\n",
    "            coo[2].extend(units)\n",
    "\n",
    "        i = torch.LongTensor(coo).to(device)\n",
    "        v = torch.FloatTensor(np.ones(len(coo[0]))).to(device)\n",
    "\n",
    "        X_batch = torch.sparse.FloatTensor(i, v, torch.Size([batch_size, num_steps, num_units])).to(device)\n",
    "        y_batch = torch.tensor(labels_[batch_index], device=device, dtype=torch.long)\n",
    "\n",
    "        yield X_batch.to(device=device), y_batch.to(device=device)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "class SurrGradSpike(torch.autograd.Function):\n",
    "    scale = 100.0  # controls steepness of surrogate gradient\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        out = torch.zeros_like(input)\n",
    "        out[input > 0] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad = grad_input / (SurrGradSpike.scale * torch.abs(input) + 1.0) ** 2\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DeepSNNModel:\n",
    "    \"\"\"\n",
    "    This class implements a simple deep snn model that comprises a set of fully connected layers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, units: List[int], weight_scale: Tuple = (7.0, 1.0), recurrent=False, time_step=1e-3,\n",
    "                 tau_mem=10e-3,\n",
    "                 tau_syn=5e-3):\n",
    "        \"\"\"\n",
    "        :param units: list of units in each layer\n",
    "        :param weight_scale: tuple of one or two values, controls the scaling of the weights\n",
    "        :param recurrent: whether the network is recurrent one - additional recurrent weights are used\n",
    "        :param time_step: how long does one time step take (seconds)\n",
    "        :param tau_mem: membrane tau parameter\n",
    "        :param tau_syn: synapse tau parameter\n",
    "        \"\"\"\n",
    "        self.units = units\n",
    "        self.tau_mem = tau_mem\n",
    "        self.tau_syn = tau_syn\n",
    "        self.alpha = float(np.exp(-time_step / tau_syn))\n",
    "        self.beta = float(np.exp(-time_step / tau_mem))\n",
    "        self.is_recurrent = recurrent\n",
    "\n",
    "        if len(weight_scale) == 2:\n",
    "            self.weight_scale = weight_scale[0] * (weight_scale[1] - self.beta)\n",
    "        else:\n",
    "            self.weight_scale = weight_scale[0]\n",
    "        self.weights = self._init_weights()\n",
    "        self.recurrent_weights = None if not recurrent else self._init_recurrent_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"\n",
    "        Initializes weights between layers\n",
    "        :return: list of torch tensors representing weights\n",
    "        \"\"\"\n",
    "        weights = []\n",
    "        for i in range(len(self.units) - 1):\n",
    "            wi = torch.empty((self.units[i], self.units[i + 1]), device=device, dtype=dtype, requires_grad=True)\n",
    "            torch.nn.init.normal_(wi, mean=0.0, std=self.weight_scale / np.sqrt(self.units[i]))\n",
    "            weights.append(wi)\n",
    "        return weights\n",
    "\n",
    "    def _init_recurrent_weights(self):\n",
    "        \"\"\"\n",
    "        Initializes recurrent weights for recurrent network for every hidden layer\n",
    "        :return: list of torch tensors representing recurrent weights\n",
    "        \"\"\"\n",
    "        recurrent_weights = []\n",
    "        for i in range(1, len(self.units) - 1):\n",
    "            vi = torch.empty((self.units[i], self.units[i]), device=device, dtype=dtype, requires_grad=True)\n",
    "            torch.nn.init.normal_(vi, mean=0.0, std=self.weight_scale / np.sqrt(self.units[i]))\n",
    "            recurrent_weights.append(vi)\n",
    "        return recurrent_weights\n",
    "\n",
    "    def run_recurrent(self, inputs, batch_size, steps, spike_fn=SurrGradSpike.apply):\n",
    "        \"\"\"\n",
    "        Runs recurrent network\n",
    "        :param inputs: input data\n",
    "        :param batch_size: batch size\n",
    "        :param steps: number of timesteps\n",
    "        :param spike_fn: surrogate gradient function\n",
    "        :return: output layer results\n",
    "        \"\"\"\n",
    "        layer_outputs = [inputs]\n",
    "        mem_recs = []\n",
    "        spike_recs = []\n",
    "\n",
    "        # compute activity in each hidden layer\n",
    "        for i in range(1, len(self.units) - 1):  # the current hidden layer index\n",
    "            hidden_units = self.units[i]  # neurons in the current hidden layer\n",
    "            syn_hidden_i = torch.zeros((batch_size, hidden_units), device=device, dtype=dtype)\n",
    "            mem_hidden_i = torch.zeros((batch_size, hidden_units), device=device, dtype=dtype)\n",
    "\n",
    "            mem_rec_hidden_i = [mem_hidden_i]\n",
    "            spike_rec_hidden_i = [mem_hidden_i]\n",
    "\n",
    "            hi = torch.zeros((batch_size, hidden_units), device=device, dtype=dtype)\n",
    "            hi_from_prev_layer = torch.einsum('abc, cd -> abd', (layer_outputs[i - 1], self.weights[i - 1]))\n",
    "\n",
    "            for dt in range(steps):\n",
    "                mem_threshold = mem_hidden_i - 1.0\n",
    "                spike_out = spike_fn(mem_threshold)\n",
    "                rst = torch.zeros_like(mem_hidden_i)\n",
    "                c = (mem_threshold > 0)\n",
    "                rst[c] = torch.ones_like(mem_hidden_i)[c]\n",
    "\n",
    "                hi = hi_from_prev_layer[:, dt] + torch.einsum('ab, bc -> ac', (hi, self.recurrent_weights[i - 1]))\n",
    "                new_syn = self.alpha * syn_hidden_i + hi\n",
    "                new_mem = self.beta * mem_hidden_i + syn_hidden_i - rst\n",
    "\n",
    "                mem_hidden_i = new_mem\n",
    "                syn_hidden_i = new_syn\n",
    "\n",
    "                mem_rec_hidden_i.append(mem_hidden_i)\n",
    "                spike_rec_hidden_i.append(spike_out)\n",
    "\n",
    "            spike_rec_hidden_i = torch.stack(spike_rec_hidden_i, dim=1)\n",
    "            mem_rec_hidden_i = torch.stack(mem_rec_hidden_i, dim=1)\n",
    "\n",
    "            layer_outputs.append(spike_rec_hidden_i)  # append output so it can be fed to the next hidden layer\n",
    "            mem_recs.append(mem_rec_hidden_i)\n",
    "            spike_recs.append(spike_rec_hidden_i)\n",
    "\n",
    "        # output layer\n",
    "        hn = torch.einsum('abc, cd -> abd', (layer_outputs[-1], self.weights[-1]))\n",
    "        flt = torch.zeros((batch_size, self.units[-1]), device=device, dtype=dtype)\n",
    "        spike_out = torch.zeros((batch_size, self.units[-1]), device=device, dtype=dtype)\n",
    "\n",
    "        out_rec = [spike_out]\n",
    "        for dt in range(steps):\n",
    "            new_flt = self.alpha * flt + hn[:, dt]\n",
    "            new_out = self.beta * spike_out + flt\n",
    "\n",
    "            flt = new_flt\n",
    "            spike_out = new_out\n",
    "\n",
    "            out_rec.append(spike_out)\n",
    "\n",
    "        out_rec = torch.stack(out_rec, dim=1)\n",
    "        return out_rec, spike_recs, layer_outputs, mem_recs\n",
    "\n",
    "    def run_feed_forward(self, inputs, batch_size, steps, spike_fn=SurrGradSpike.apply):\n",
    "        \"\"\"\n",
    "        Run feed forward network in the same manner as a recurrent one except that no recurrent weights are calculated\n",
    "        :param inputs: input data\n",
    "        :param batch_size: batch size\n",
    "        :param steps: number of time steps\n",
    "        :param spike_fn: surrogate gradient function\n",
    "        :return: output layer results\n",
    "        \"\"\"\n",
    "        layer_outputs = [inputs]\n",
    "        mem_recs = []\n",
    "        spike_recs = []\n",
    "\n",
    "        # compute activity of every hidden layer\n",
    "        # hidden layers are stored from index 1 to index len(self.units) - 2\n",
    "        for i in range(1, len(self.units) - 1):\n",
    "            hidden_units = self.units[i]  # units in next layer\n",
    "\n",
    "            # sum of output from previous layer and weights of current hidden layer\n",
    "            hi = torch.einsum('abc,cd->abd', (layer_outputs[i - 1], self.weights[i - 1]))\n",
    "            syn_hidden_i = torch.zeros((batch_size, hidden_units), device=device, dtype=dtype)  # synapses\n",
    "            mem_hidden_i = torch.zeros((batch_size, hidden_units), device=device, dtype=dtype)  # membranes\n",
    "\n",
    "            mem_rec_hidden_i = [mem_hidden_i]\n",
    "            spike_rec_hidden_i = [mem_hidden_i]\n",
    "\n",
    "            for dt in range(steps):\n",
    "                mem_threshold = mem_hidden_i - 1.0\n",
    "                spike_out = spike_fn(mem_threshold)\n",
    "                rst = torch.zeros_like(mem_hidden_i)\n",
    "                c = (mem_threshold > 0)\n",
    "                rst[c] = torch.ones_like(mem_hidden_i)[c]\n",
    "\n",
    "                new_syn = self.alpha * syn_hidden_i + hi[:, dt]\n",
    "                new_mem = self.beta * mem_hidden_i + syn_hidden_i - rst\n",
    "                mem_hidden_i = new_mem\n",
    "                syn_hidden_i = new_syn\n",
    "\n",
    "                mem_rec_hidden_i.append(mem_hidden_i)\n",
    "                spike_rec_hidden_i.append(spike_out)\n",
    "\n",
    "            spike_rec_hidden_i = torch.stack(spike_rec_hidden_i, dim=1)\n",
    "            mem_rec_hidden_i = torch.stack(mem_rec_hidden_i, dim=1)\n",
    "\n",
    "            layer_outputs.append(spike_rec_hidden_i)  # append output so it can be fed to the next hidden layer\n",
    "            mem_recs.append(mem_rec_hidden_i)\n",
    "            spike_recs.append(spike_rec_hidden_i)\n",
    "\n",
    "        # readout layer\n",
    "        hn = torch.einsum('abc,cd->abd', (layer_outputs[-1], self.weights[-1]))\n",
    "        flt = torch.zeros((batch_size, self.units[-1]), device=device, dtype=dtype)\n",
    "        spike_out = torch.zeros((batch_size, self.units[-1]), device=device, dtype=dtype)\n",
    "\n",
    "        out_rec = [spike_out]\n",
    "        for dt in range(steps):\n",
    "            new_flt = self.alpha * flt + hn[:, dt]\n",
    "            new_out = self.beta * spike_out + flt\n",
    "            flt = new_flt\n",
    "            spike_out = new_out\n",
    "            out_rec.append(spike_out)\n",
    "\n",
    "        out_rec = torch.stack(out_rec, dim=1)\n",
    "        return out_rec, spike_recs, layer_outputs, mem_recs\n",
    "\n",
    "    def train(self, x_data, y_data, batch_size, num_steps=100, time_step=1e-3, lr=1e-3, num_epochs=10):\n",
    "        \"\"\"\n",
    "        Train the network\n",
    "        :param x_data: features (training data)\n",
    "        :param y_data: labels (training)\n",
    "        :param batch_size: number of elements per batch\n",
    "        :param num_steps: number of time steps\n",
    "        :param time_step: how long does a time step take (s)\n",
    "        :param lr: learning rate\n",
    "        :param num_epochs: number of epochs for training\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # Create optimizer, and loss function\n",
    "        optimizer = torch.optim.Adam(self.weights, lr=lr, betas=(0.9, 0.999))\n",
    "        log_softmax_fn = nn.LogSoftmax(dim=1)\n",
    "        loss_fn = nn.NLLLoss()\n",
    "\n",
    "        # Begin training\n",
    "        loss_hist = []\n",
    "        for epoch in range(num_epochs):\n",
    "            local_loss = []\n",
    "            for x_local, y_local in sparse_data_generator(x_data, y_data, batch_size, num_steps, self.units[0],\n",
    "                                                          time_step):\n",
    "\n",
    "                if not self.is_recurrent:  # if the network does not contain recurrent weights run it as feedforward\n",
    "                    output, spike_recs, layer_outputs, mem_recs = self.run_feed_forward(x_local.to_dense(), batch_size,\n",
    "                                                                                        num_steps)\n",
    "                else:\n",
    "                    output, spike_recs, layer_outputs, mem_recs = self.run_recurrent(x_local.to_dense(), batch_size,\n",
    "                                                                                     num_steps)\n",
    "\n",
    "                output_max, _ = torch.max(output, 1)\n",
    "                log_p_y = log_softmax_fn(output_max) # apply log softmax function\n",
    "\n",
    "                loss_val = loss_fn(log_p_y, y_local) # calculate the loss\n",
    "\n",
    "                # Perform the optimization\n",
    "                optimizer.zero_grad()\n",
    "                loss_val.backward()\n",
    "                optimizer.step()\n",
    "                local_loss.append(loss_val.item())\n",
    "\n",
    "            mean_loss = np.mean(local_loss)\n",
    "            print('Epoch {}: loss={:.5f}'.format(epoch + 1, mean_loss)) # log the loss to console\n",
    "            loss_hist.append(mean_loss)\n",
    "\n",
    "        return loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_metrics(x_test, y_test, batch_size, snn_model, time_step=1e-3, num_steps=100):\n",
    "    \"\"\"\n",
    "    Calculate metrics for the network\n",
    "    :param x_test: testing features\n",
    "    :param y_test: testing labels\n",
    "    :param batch_size: number of elements per batch\n",
    "    :param snn_model: reference to the trained snn model\n",
    "    :param time_step: how long does a time step take (s)\n",
    "    :param num_steps: number of time steps\n",
    "    :return: accuracy, precision, recall, f1 metric and confusion matrix\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "\n",
    "    # Truncate the remaining number of samples according to batch size\n",
    "    samples = (x_test.shape[0] // batch_size ) * batch_size\n",
    "    x_test, y_test = x_test[:samples], y_test[:samples]\n",
    "    for x_local, y_local in sparse_data_generator(x_test, y_test, batch_size, num_steps, snn_model.units[0], time_step,\n",
    "                                                  False):\n",
    "\n",
    "        # Run feedforward/recurrent network and get the output\n",
    "        output, spike_recs, layer_outputs, mem_recs = snn_model.run_recurrent(x_local.to_dense(), batch_size, num_steps) \\\n",
    "            if snn_model.recurrent_weights else snn_model.run_feed_forward(x_local.to_dense(), batch_size, num_steps)\n",
    "\n",
    "        output_max, _ = torch.max(output, 1)\n",
    "        _, output_argmax = torch.max(output_max, 1)\n",
    "\n",
    "        # Append the current batch\n",
    "        predictions.append(output_argmax)\n",
    "\n",
    "    # Concatenate to a single tensor\n",
    "    predictions = torch.cat(predictions)\n",
    "\n",
    "    # Map to numpy\n",
    "    predictions = predictions.cpu().detach().numpy()\n",
    "\n",
    "    # Now calculate the metrics\n",
    "    # Use the \"micro\" average - i.e. the calculation is done globally, counting total number of tp, fp and fn for\n",
    "    # each class\n",
    "    precision = metrics.precision_score(y_true=y_test, y_pred=predictions, average='macro')\n",
    "    recall = metrics.recall_score(y_true=y_test, y_pred=predictions, average='macro')\n",
    "    f1 = metrics.f1_score(y_true=y_test, y_pred=predictions, average='macro')\n",
    "    accuracy = metrics.accuracy_score(y_true=y_test, y_pred=predictions)\n",
    "    confusion_matrix = metrics.confusion_matrix(y_true=y_test, y_pred=predictions)\n",
    "\n",
    "    # Return the metrics\n",
    "    return accuracy, precision, recall, f1, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to cached_datasets\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61.7%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "98.7%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "102.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting cached_datasets\\MNIST\\raw\\train-labels-idx1-ubyte.gz to cached_datasets\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to cached_datasets\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting cached_datasets\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to cached_datasets\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to cached_datasets\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting cached_datasets\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to cached_datasets\\MNIST\\raw\n",
      "\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\dev\\anaconda\\envs\\conda_tutorial\\lib\\site-packages\\torchvision\\datasets\\mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# Download datasets through PyTorch (if necessary)\n",
    "dataset_folder = os.path.join('cached_datasets')\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(dataset_folder, train=True,\n",
    "                                           transform=None, target_transform=None, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(dataset_folder, train=False,\n",
    "                                          transform=None, target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The MNIST dataset is ready.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declaration of models that will be tested on the MNIST and the Fashion MNIST datasets\n",
    "models_mnist = [\n",
    "    DeepSNNModel([28*28, 256, 128, 10]),\n",
    "    DeepSNNModel([28*28, 256, 128, 64, 10]),\n",
    "    DeepSNNModel([28*28, 256, 128, 10], recurrent=True),\n",
    "    DeepSNNModel([28*28, 256, 128, 64, 10], recurrent=True)\n",
    "]\n",
    "\n",
    "# Standardize the MNIST dataset\n",
    "mnist_x_train = np.array(train_dataset.data, dtype=np.float)\n",
    "mnist_x_train = mnist_x_train.reshape(mnist_x_train.shape[0], -1) / 255\n",
    "mnist_x_test = np.array(test_dataset.data, dtype=np.float)\n",
    "mnist_x_test = mnist_x_test.reshape(mnist_x_test.shape[0], -1) / 255\n",
    "\n",
    "mnist_y_train = np.array(train_dataset.targets, dtype=np.int)\n",
    "mnist_y_test = np.array(test_dataset.targets, dtype=np.int)\n",
    "\n",
    "'The MNIST dataset is ready.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running benchmark on MNIST dataset\n",
      "Epoch 1: loss=0.41898\n",
      "Epoch 2: loss=0.17241\n",
      "Epoch 3: loss=0.13497\n",
      "Epoch 4: loss=0.11038\n",
      "Epoch 5: loss=0.10026\n"
     ]
    }
   ],
   "source": [
    "print('Running benchmark on MNIST dataset')\n",
    "\n",
    "# Array for statistics of each model\n",
    "mnist_stats = []\n",
    "\n",
    "# Run each model\n",
    "for i, model in enumerate(models_mnist):\n",
    "    model.train(mnist_x_train, mnist_y_train, 256, num_epochs=30)\n",
    "    accuracy, precision, recall, f1, confusion_matrix = get_metrics(mnist_x_test, mnist_y_test, 256, model)\n",
    "    stats = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': confusion_matrix\n",
    "    }\n",
    "\n",
    "    print(f'Model {i+1}: {stats}')\n",
    "    mnist_stats.append(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fashion MNIST\n",
    "train_dataset = torchvision.datasets.FashionMNIST(dataset_folder, train=True,\n",
    "                                           transform=None, target_transform=None, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(dataset_folder, train=False,\n",
    "                                          transform=None, target_transform=None, download=True)\n",
    "\n",
    "# Create the same models for the Fashion MNIST dataset\n",
    "models_fashion_mnist = [\n",
    "    DeepSNNModel([28*28, 256, 128, 10]),\n",
    "    DeepSNNModel([28*28, 256, 128, 64, 10]),\n",
    "    DeepSNNModel([28*28, 256, 128, 10], recurrent=True),\n",
    "    DeepSNNModel([28*28, 256, 128, 64, 10], recurrent=True)\n",
    "]\n",
    "\n",
    "# Standardize the data\n",
    "fmnist_x_train = np.array(train_dataset.data, dtype=np.float)\n",
    "fmnist_x_train = fmnist_x_train.reshape(fmnist_x_train.shape[0], -1) / 255\n",
    "fmnist_x_test = np.array(test_dataset.data, dtype=np.float)\n",
    "fmnist_x_test = fmnist_x_test.reshape(fmnist_x_test.shape[0], -1) / 255\n",
    "\n",
    "fmnist_y_train = np.array(train_dataset.targets, dtype=np.int)\n",
    "fmnist_y_test = np.array(test_dataset.targets, dtype=np.int)\n",
    "\n",
    "fashion_mnist_stats = []\n",
    "i = 1\n",
    "for i, model in enumerate(models_fashion_mnist):\n",
    "    model.train(mnist_x_train, mnist_y_train, 256, num_epochs=30) # train the model\n",
    "\n",
    "    # Get metrics\n",
    "    accuracy, precision, recall, f1, confusion_matrix = get_metrics(mnist_x_test, mnist_y_test, 256, model)\n",
    "\n",
    "    # Create dictionary for later use\n",
    "    stats = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': confusion_matrix\n",
    "    }\n",
    "\n",
    "    # Print and save the stats\n",
    "    print(f'Model {i+1}: {stats}')\n",
    "    fashion_mnist_stats.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mnist_df = pd.DataFrame({\n",
    "    'model': [f'{i}' for i in range(1, len(models_mnist) + 1)],\n",
    "    'accuracy': [x['accuracy'] for x in mnist_stats],\n",
    "    'precision': [x['precision'] for x in mnist_stats],\n",
    "    'recall': [x['recall'] for x in mnist_stats],\n",
    "    'f1': [x['f1'] for x in mnist_stats],\n",
    "})\n",
    "\n",
    "mnist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print confusion matrix for each model\n",
    "print('Confusion Matrices:')\n",
    "for confusion_matrix in map(lambda x: x['confusion_matrix'], mnist_stats):\n",
    "    print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create output directory to save the results\n",
    "output_path = 'results'\n",
    "os.makedirs(output_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save as XLSX (excel) file\n",
    "mnist_df.to_excel(os.path.join(output_path, 'mnist_results.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fmnist_df = pd.DataFrame({\n",
    "    'model': [f'{i}' for i in range(1, len(models_fashion_mnist))],\n",
    "    'accuracy': [x['accuracy'] for x in fashion_mnist_stats],\n",
    "    'precision': [x['precision'] for x in fashion_mnist_stats],\n",
    "    'recall': [x['recall'] for x in fashion_mnist_stats],\n",
    "    'f1': [x['f1'] for x in fashion_mnist_stats],\n",
    "})\n",
    "\n",
    "fmnist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print confusion matrix for each model\n",
    "print('Confusion Matrices:')\n",
    "for confusion_matrix in map(lambda x: x['confusion_matrix'], fashion_mnist_stats):\n",
    "    print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save as XLSX\n",
    "fmnist_df.to_excel(os.path.join(output_path, 'fashion_mnist_results.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}