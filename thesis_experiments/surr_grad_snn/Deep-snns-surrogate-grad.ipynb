{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This notebook was used to perform training and evaluation of a simple two-hidden-layer and three-hidden layers on\n",
    "MNIST and Fashion MNIST datasets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seed for consistent behavior (though different results will still occur due to computation on GPU - if present)\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set the device for computation\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set data type for computations in the neural network\n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Function to convert the inputs into spikes\n",
    "def convert_to_firing_time(x, tau=20, thr=0.2, tmax=1.0, epsilon=1e-7):\n",
    "    idx = x < thr\n",
    "    x = np.clip(x, thr + epsilon, 1e9)\n",
    "    T = tau * np.log(x / (x - thr))\n",
    "    T[idx] = tmax\n",
    "    return T\n",
    "\n",
    "# This function is used to generate features and labels for the simulator in batches\n",
    "def sparse_data_generator(x, y, batch_size, num_steps, num_units, time_step=1e-3, shuffle=True):\n",
    "\n",
    "    labels_ = np.array(y, dtype=np.int)\n",
    "    number_of_batches = len(x) // batch_size\n",
    "    sample_index = np.arange(len(x))\n",
    "\n",
    "    # compute discrete firing times\n",
    "    tau_eff = 20e-3 / time_step\n",
    "    firing_times = np.array(convert_to_firing_time(x, tau=tau_eff, tmax=num_steps), dtype=np.int)\n",
    "    unit_numbers = np.arange(num_units)\n",
    "\n",
    "    # shuffle if set to True\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "\n",
    "    counter = 0\n",
    "    while counter < number_of_batches:\n",
    "        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n",
    "\n",
    "        coo = [[] for _ in range(3)]\n",
    "        for bc, idx in enumerate(batch_index):\n",
    "            c = firing_times[idx] < num_steps\n",
    "            times, units = firing_times[idx][c], unit_numbers[c]\n",
    "\n",
    "            batch = [bc for _ in range(len(times))]\n",
    "            coo[0].extend(batch)\n",
    "            coo[1].extend(times)\n",
    "            coo[2].extend(units)\n",
    "\n",
    "        i = torch.LongTensor(coo).to(device)\n",
    "        v = torch.FloatTensor(np.ones(len(coo[0]))).to(device)\n",
    "\n",
    "        X_batch = torch.sparse.FloatTensor(i, v, torch.Size([batch_size, num_steps, num_units])).to(device)\n",
    "        y_batch = torch.tensor(labels_[batch_index], device=device, dtype=torch.long)\n",
    "\n",
    "        yield X_batch.to(device=device), y_batch.to(device=device)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "class SurrGradSpike(torch.autograd.Function):\n",
    "    scale = 100.0  # controls steepness of surrogate gradient\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        out = torch.zeros_like(input)\n",
    "        out[input > 0] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad = grad_input / (SurrGradSpike.scale * torch.abs(input) + 1.0) ** 2\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DeepSNNModel:\n",
    "    \"\"\"\n",
    "    This class implements a simple deep snn model that comprises a set of fully connected layers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, units: List[int], weight_scale: Tuple = (7.0, 1.0), recurrent=False, time_step=1e-3,\n",
    "                 tau_mem=10e-3,\n",
    "                 tau_syn=5e-3):\n",
    "        \"\"\"\n",
    "        :param units: list of units in each layer\n",
    "        :param weight_scale: tuple of one or two values, controls the scaling of the weights\n",
    "        :param recurrent: whether the network is recurrent one - additional recurrent weights are used\n",
    "        :param time_step: how long does one time step take (seconds)\n",
    "        :param tau_mem: membrane tau parameter\n",
    "        :param tau_syn: synapse tau parameter\n",
    "        \"\"\"\n",
    "        self.units = units\n",
    "        self.tau_mem = tau_mem\n",
    "        self.tau_syn = tau_syn\n",
    "        self.alpha = float(np.exp(-time_step / tau_syn))\n",
    "        self.beta = float(np.exp(-time_step / tau_mem))\n",
    "        self.is_recurrent = recurrent\n",
    "\n",
    "        if len(weight_scale) == 2:\n",
    "            self.weight_scale = weight_scale[0] * (weight_scale[1] - self.beta)\n",
    "        else:\n",
    "            self.weight_scale = weight_scale[0]\n",
    "        self.weights = self._init_weights()\n",
    "        self.recurrent_weights = None if not recurrent else self._init_recurrent_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"\n",
    "        Initializes weights between layers\n",
    "        :return: list of torch tensors representing weights\n",
    "        \"\"\"\n",
    "        weights = []\n",
    "        for i in range(len(self.units) - 1):\n",
    "            wi = torch.empty((self.units[i], self.units[i + 1]), device=device, dtype=dtype, requires_grad=True)\n",
    "            torch.nn.init.normal_(wi, mean=0.0, std=self.weight_scale / np.sqrt(self.units[i]))\n",
    "            weights.append(wi)\n",
    "        return weights\n",
    "\n",
    "    def _init_recurrent_weights(self):\n",
    "        \"\"\"\n",
    "        Initializes recurrent weights for recurrent network for every hidden layer\n",
    "        :return: list of torch tensors representing recurrent weights\n",
    "        \"\"\"\n",
    "        recurrent_weights = []\n",
    "        for i in range(1, len(self.units) - 1):\n",
    "            vi = torch.empty((self.units[i], self.units[i]), device=device, dtype=dtype, requires_grad=True)\n",
    "            torch.nn.init.normal_(vi, mean=0.0, std=self.weight_scale / np.sqrt(self.units[i]))\n",
    "            recurrent_weights.append(vi)\n",
    "        return recurrent_weights\n",
    "\n",
    "    def run_recurrent(self, inputs, batch_size, steps, spike_fn=SurrGradSpike.apply):\n",
    "        \"\"\"\n",
    "        Runs recurrent network\n",
    "        :param inputs: input data\n",
    "        :param batch_size: batch size\n",
    "        :param steps: number of timesteps\n",
    "        :param spike_fn: surrogate gradient function\n",
    "        :return: output layer results\n",
    "        \"\"\"\n",
    "        layer_outputs = [inputs]\n",
    "        mem_recs = []\n",
    "        spike_recs = []\n",
    "\n",
    "        # compute activity in each hidden layer\n",
    "        for i in range(1, len(self.units) - 1):  # the current hidden layer index\n",
    "            hidden_units = self.units[i]  # neurons in the current hidden layer\n",
    "            syn_hidden_i = torch.zeros((batch_size, hidden_units), device=device, dtype=dtype)\n",
    "            mem_hidden_i = torch.zeros((batch_size, hidden_units), device=device, dtype=dtype)\n",
    "\n",
    "            mem_rec_hidden_i = [mem_hidden_i]\n",
    "            spike_rec_hidden_i = [mem_hidden_i]\n",
    "\n",
    "            hi = torch.zeros((batch_size, hidden_units), device=device, dtype=dtype)\n",
    "            hi_from_prev_layer = torch.einsum('abc, cd -> abd', (layer_outputs[i - 1], self.weights[i - 1]))\n",
    "\n",
    "            for dt in range(steps):\n",
    "                mem_threshold = mem_hidden_i - 1.0\n",
    "                spike_out = spike_fn(mem_threshold)\n",
    "                rst = torch.zeros_like(mem_hidden_i)\n",
    "                c = (mem_threshold > 0)\n",
    "                rst[c] = torch.ones_like(mem_hidden_i)[c]\n",
    "\n",
    "                hi = hi_from_prev_layer[:, dt] + torch.einsum('ab, bc -> ac', (hi, self.recurrent_weights[i - 1]))\n",
    "                new_syn = self.alpha * syn_hidden_i + hi\n",
    "                new_mem = self.beta * mem_hidden_i + syn_hidden_i - rst\n",
    "\n",
    "                mem_hidden_i = new_mem\n",
    "                syn_hidden_i = new_syn\n",
    "\n",
    "                mem_rec_hidden_i.append(mem_hidden_i)\n",
    "                spike_rec_hidden_i.append(spike_out)\n",
    "\n",
    "            spike_rec_hidden_i = torch.stack(spike_rec_hidden_i, dim=1)\n",
    "            mem_rec_hidden_i = torch.stack(mem_rec_hidden_i, dim=1)\n",
    "\n",
    "            layer_outputs.append(spike_rec_hidden_i)  # append output so it can be fed to the next hidden layer\n",
    "            mem_recs.append(mem_rec_hidden_i)\n",
    "            spike_recs.append(spike_rec_hidden_i)\n",
    "\n",
    "        # output layer\n",
    "        hn = torch.einsum('abc, cd -> abd', (layer_outputs[-1], self.weights[-1]))\n",
    "        flt = torch.zeros((batch_size, self.units[-1]), device=device, dtype=dtype)\n",
    "        spike_out = torch.zeros((batch_size, self.units[-1]), device=device, dtype=dtype)\n",
    "\n",
    "        out_rec = [spike_out]\n",
    "        for dt in range(steps):\n",
    "            new_flt = self.alpha * flt + hn[:, dt]\n",
    "            new_out = self.beta * spike_out + flt\n",
    "\n",
    "            flt = new_flt\n",
    "            spike_out = new_out\n",
    "\n",
    "            out_rec.append(spike_out)\n",
    "\n",
    "        out_rec = torch.stack(out_rec, dim=1)\n",
    "        return out_rec, spike_recs, layer_outputs, mem_recs\n",
    "\n",
    "    def run_feed_forward(self, inputs, batch_size, steps, spike_fn=SurrGradSpike.apply):\n",
    "        \"\"\"\n",
    "        Run feed forward network in the same manner as a recurrent one except that no recurrent weights are calculated\n",
    "        :param inputs: input data\n",
    "        :param batch_size: batch size\n",
    "        :param steps: number of time steps\n",
    "        :param spike_fn: surrogate gradient function\n",
    "        :return: output layer results\n",
    "        \"\"\"\n",
    "        layer_outputs = [inputs]\n",
    "        mem_recs = []\n",
    "        spike_recs = []\n",
    "\n",
    "        # compute activity of every hidden layer\n",
    "        # hidden layers are stored from index 1 to index len(self.units) - 2\n",
    "        for i in range(1, len(self.units) - 1):\n",
    "            hidden_units = self.units[i]  # units in next layer\n",
    "\n",
    "            # sum of output from previous layer and weights of current hidden layer\n",
    "            hi = torch.einsum('abc,cd->abd', (layer_outputs[i - 1], self.weights[i - 1]))\n",
    "            syn_hidden_i = torch.zeros((batch_size, hidden_units), device=device, dtype=dtype)  # synapses\n",
    "            mem_hidden_i = torch.zeros((batch_size, hidden_units), device=device, dtype=dtype)  # membranes\n",
    "\n",
    "            mem_rec_hidden_i = [mem_hidden_i]\n",
    "            spike_rec_hidden_i = [mem_hidden_i]\n",
    "\n",
    "            for dt in range(steps):\n",
    "                mem_threshold = mem_hidden_i - 1.0\n",
    "                spike_out = spike_fn(mem_threshold)\n",
    "                rst = torch.zeros_like(mem_hidden_i)\n",
    "                c = (mem_threshold > 0)\n",
    "                rst[c] = torch.ones_like(mem_hidden_i)[c]\n",
    "\n",
    "                new_syn = self.alpha * syn_hidden_i + hi[:, dt]\n",
    "                new_mem = self.beta * mem_hidden_i + syn_hidden_i - rst\n",
    "                mem_hidden_i = new_mem\n",
    "                syn_hidden_i = new_syn\n",
    "\n",
    "                mem_rec_hidden_i.append(mem_hidden_i)\n",
    "                spike_rec_hidden_i.append(spike_out)\n",
    "\n",
    "            spike_rec_hidden_i = torch.stack(spike_rec_hidden_i, dim=1)\n",
    "            mem_rec_hidden_i = torch.stack(mem_rec_hidden_i, dim=1)\n",
    "\n",
    "            layer_outputs.append(spike_rec_hidden_i)  # append output so it can be fed to the next hidden layer\n",
    "            mem_recs.append(mem_rec_hidden_i)\n",
    "            spike_recs.append(spike_rec_hidden_i)\n",
    "\n",
    "        # readout layer\n",
    "        hn = torch.einsum('abc,cd->abd', (layer_outputs[-1], self.weights[-1]))\n",
    "        flt = torch.zeros((batch_size, self.units[-1]), device=device, dtype=dtype)\n",
    "        spike_out = torch.zeros((batch_size, self.units[-1]), device=device, dtype=dtype)\n",
    "\n",
    "        out_rec = [spike_out]\n",
    "        for dt in range(steps):\n",
    "            new_flt = self.alpha * flt + hn[:, dt]\n",
    "            new_out = self.beta * spike_out + flt\n",
    "            flt = new_flt\n",
    "            spike_out = new_out\n",
    "            out_rec.append(spike_out)\n",
    "\n",
    "        out_rec = torch.stack(out_rec, dim=1)\n",
    "        return out_rec, spike_recs, layer_outputs, mem_recs\n",
    "\n",
    "    def train(self, x_data, y_data, batch_size, num_steps=100, time_step=1e-3, lr=1e-3, num_epochs=10):\n",
    "        \"\"\"\n",
    "        Train the network\n",
    "        :param x_data: features (training data)\n",
    "        :param y_data: labels (training)\n",
    "        :param batch_size: number of elements per batch\n",
    "        :param num_steps: number of time steps\n",
    "        :param time_step: how long does a time step take (s)\n",
    "        :param lr: learning rate\n",
    "        :param num_epochs: number of epochs for training\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # Create optimizer, and loss function\n",
    "        optimizer = torch.optim.Adam(self.weights, lr=lr, betas=(0.9, 0.999))\n",
    "        log_softmax_fn = nn.LogSoftmax(dim=1)\n",
    "        loss_fn = nn.NLLLoss()\n",
    "\n",
    "        # Begin training\n",
    "        loss_hist = []\n",
    "        for epoch in range(num_epochs):\n",
    "            local_loss = []\n",
    "            for x_local, y_local in sparse_data_generator(x_data, y_data, batch_size, num_steps, self.units[0],\n",
    "                                                          time_step):\n",
    "\n",
    "                if not self.is_recurrent:  # if the network does not contain recurrent weights run it as feedforward\n",
    "                    output, spike_recs, layer_outputs, mem_recs = self.run_feed_forward(x_local.to_dense(), batch_size,\n",
    "                                                                                        num_steps)\n",
    "                else:\n",
    "                    output, spike_recs, layer_outputs, mem_recs = self.run_recurrent(x_local.to_dense(), batch_size,\n",
    "                                                                                     num_steps)\n",
    "\n",
    "                output_max, _ = torch.max(output, 1)\n",
    "                log_p_y = log_softmax_fn(output_max) # apply log softmax function\n",
    "\n",
    "                loss_val = loss_fn(log_p_y, y_local) # calculate the loss\n",
    "\n",
    "                # Perform the optimization\n",
    "                optimizer.zero_grad()\n",
    "                loss_val.backward()\n",
    "                optimizer.step()\n",
    "                local_loss.append(loss_val.item())\n",
    "\n",
    "            mean_loss = np.mean(local_loss)\n",
    "            print('Epoch {}: loss={:.5f}'.format(epoch + 1, mean_loss)) # log the loss to console\n",
    "            loss_hist.append(mean_loss)\n",
    "\n",
    "        return loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def get_metrics(x_test, y_test, batch_size, snn_model, time_step=1e-3, num_steps=100):\n",
    "    \"\"\"\n",
    "    Calculate metrics for the network\n",
    "    :param x_test: testing features\n",
    "    :param y_test: testing labels\n",
    "    :param batch_size: number of elements per batch\n",
    "    :param snn_model: reference to the trained snn model\n",
    "    :param time_step: how long does a time step take (s)\n",
    "    :param num_steps: number of time steps\n",
    "    :return: accuracy, precision, recall, f1 metric and confusion matrix\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "\n",
    "    # Truncate the remaining number of samples according to batch size\n",
    "    samples = (x_test.shape[0] // batch_size ) * batch_size\n",
    "    x_test, y_test = x_test[:samples], y_test[:samples]\n",
    "    for x_local, y_local in sparse_data_generator(x_test, y_test, batch_size, num_steps, snn_model.units[0], time_step,\n",
    "                                                  False):\n",
    "\n",
    "        # Run feedforward/recurrent network and get the output\n",
    "        output, spike_recs, layer_outputs, mem_recs = snn_model.run_recurrent(x_local.to_dense(), batch_size, num_steps) \\\n",
    "            if snn_model.recurrent_weights else snn_model.run_feed_forward(x_local.to_dense(), batch_size, num_steps)\n",
    "\n",
    "        output_max, _ = torch.max(output, 1)\n",
    "        _, output_argmax = torch.max(output_max, 1)\n",
    "\n",
    "        # Append the current batch\n",
    "        predictions.append(output_argmax)\n",
    "\n",
    "    # Concatenate to a single tensor\n",
    "    predictions = torch.cat(predictions)\n",
    "\n",
    "    # Map to numpy\n",
    "    predictions = predictions.cpu().detach().numpy()\n",
    "\n",
    "    # Now calculate the metrics\n",
    "    # Use the \"micro\" average - i.e. the calculation is done globally, counting total number of tp, fp and fn for\n",
    "    # each class\n",
    "    precision = metrics.precision_score(y_true=y_test, y_pred=predictions, average='macro')\n",
    "    recall = metrics.recall_score(y_true=y_test, y_pred=predictions, average='macro')\n",
    "    f1 = metrics.f1_score(y_true=y_test, y_pred=predictions, average='macro')\n",
    "    accuracy = metrics.accuracy_score(y_true=y_test, y_pred=predictions)\n",
    "    confusion_matrix = metrics.confusion_matrix(y_true=y_test, y_pred=predictions)\n",
    "\n",
    "    # Return the metrics\n",
    "    return accuracy, precision, recall, f1, confusion_matrix\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Download datasets through PyTorch (if necessary)\n",
    "dataset_folder = os.path.join('cached_datasets')\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(dataset_folder, train=True,\n",
    "                                           transform=None, target_transform=None, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(dataset_folder, train=False,\n",
    "                                          transform=None, target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "'The MNIST dataset is ready.'"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declaration of models that will be tested on the MNIST and the Fashion MNIST datasets\n",
    "models_mnist = [\n",
    "    DeepSNNModel([28*28, 256, 128, 10]),\n",
    "    DeepSNNModel([28*28, 256, 128, 64, 10]),\n",
    "    DeepSNNModel([28*28, 256, 128, 10], recurrent=True),\n",
    "    DeepSNNModel([28*28, 256, 128, 64, 10], recurrent=True)\n",
    "]\n",
    "\n",
    "# Standardize the MNIST dataset\n",
    "mnist_x_train = np.array(train_dataset.data, dtype=np.float)\n",
    "mnist_x_train = mnist_x_train.reshape(mnist_x_train.shape[0], -1) / 255\n",
    "mnist_x_test = np.array(test_dataset.data, dtype=np.float)\n",
    "mnist_x_test = mnist_x_test.reshape(mnist_x_test.shape[0], -1) / 255\n",
    "\n",
    "mnist_y_train = np.array(train_dataset.targets, dtype=np.int)\n",
    "mnist_y_test = np.array(test_dataset.targets, dtype=np.int)\n",
    "\n",
    "'The MNIST dataset is ready.'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running benchmark on MNIST dataset\n",
      "Epoch 1: loss=0.41898\n",
      "Epoch 2: loss=0.17241\n",
      "Epoch 3: loss=0.13497\n",
      "Epoch 4: loss=0.11038\n",
      "Epoch 5: loss=0.10026\n",
      "Epoch 6: loss=0.08224\n",
      "Epoch 7: loss=0.07420\n",
      "Epoch 8: loss=0.06370\n",
      "Epoch 9: loss=0.06477\n",
      "Epoch 10: loss=0.05850\n",
      "Epoch 11: loss=0.05357\n",
      "Epoch 12: loss=0.04823\n",
      "Epoch 13: loss=0.04377\n",
      "Epoch 14: loss=0.04931\n",
      "Epoch 15: loss=0.04287\n",
      "Epoch 16: loss=0.03852\n",
      "Epoch 17: loss=0.03905\n",
      "Epoch 18: loss=0.03719\n",
      "Epoch 19: loss=0.04059\n",
      "Epoch 20: loss=0.03788\n",
      "Epoch 21: loss=0.02963\n",
      "Epoch 22: loss=0.03222\n",
      "Epoch 23: loss=0.03603\n",
      "Epoch 24: loss=0.03475\n",
      "Epoch 25: loss=0.02788\n",
      "Epoch 26: loss=0.02541\n",
      "Epoch 27: loss=0.02777\n",
      "Epoch 28: loss=0.03440\n",
      "Epoch 29: loss=0.03188\n",
      "Epoch 30: loss=0.03120\n",
      "Model 0: {'accuracy': 0.9697516025641025, 'precision': 0.9697470178734366, 'recall': 0.9695371760516318, 'f1': 0.9694956147153926, 'confusion_matrix': array([[ 972,    0,    0,    2,    0,    0,    1,    0,    2,    2],\n",
      "       [   3, 1115,    3,    1,    2,    1,    4,    1,    3,    0],\n",
      "       [  10,    0,  991,    5,    3,    0,    1,    6,   13,    1],\n",
      "       [   1,    0,    7,  975,    0,    7,    0,    7,   10,    1],\n",
      "       [   0,    0,    1,    0,  969,    0,    3,    1,    1,    5],\n",
      "       [   4,    0,    0,   17,    1,  847,    9,    2,    9,    1],\n",
      "       [   9,    2,    0,    0,    4,    2,  937,    1,    1,    0],\n",
      "       [   3,    8,    6,    3,    1,    0,    1,  989,    8,    8],\n",
      "       [  12,    1,    2,    3,    6,    2,    4,    2,  936,    5],\n",
      "       [  10,    3,    0,    5,   25,    4,    0,    3,    7,  951]],\n",
      "      dtype=int64)}\n",
      "Epoch 1: loss=0.71662\n",
      "Epoch 2: loss=0.28210\n",
      "Epoch 3: loss=0.22230\n",
      "Epoch 4: loss=0.20050\n",
      "Epoch 5: loss=0.17038\n",
      "Epoch 6: loss=0.16065\n",
      "Epoch 7: loss=0.13212\n",
      "Epoch 8: loss=0.14455\n",
      "Epoch 9: loss=0.12911\n",
      "Epoch 10: loss=0.11420\n",
      "Epoch 11: loss=0.11598\n",
      "Epoch 12: loss=0.10371\n",
      "Epoch 13: loss=0.10047\n",
      "Epoch 14: loss=0.09710\n",
      "Epoch 15: loss=0.09119\n",
      "Epoch 16: loss=0.08214\n",
      "Epoch 17: loss=0.07925\n",
      "Epoch 18: loss=0.08945\n",
      "Epoch 19: loss=0.08181\n",
      "Epoch 20: loss=0.08917\n",
      "Epoch 21: loss=0.07536\n",
      "Epoch 22: loss=0.07131\n",
      "Epoch 23: loss=0.07425\n",
      "Epoch 24: loss=0.06837\n",
      "Epoch 25: loss=0.06051\n",
      "Epoch 26: loss=0.06123\n",
      "Epoch 27: loss=0.05879\n",
      "Epoch 28: loss=0.05450\n",
      "Epoch 29: loss=0.05627\n",
      "Epoch 30: loss=0.07322\n",
      "Model 1: {'accuracy': 0.9637419871794872, 'precision': 0.9637299539584477, 'recall': 0.9630776556721651, 'f1': 0.9632994660843522, 'confusion_matrix': array([[ 968,    0,    0,    0,    1,    0,    2,    1,    5,    2],\n",
      "       [   1, 1118,    3,    1,    0,    0,    3,    1,    6,    0],\n",
      "       [   5,    1,  992,    8,    2,    0,    3,    8,    9,    2],\n",
      "       [   1,    1,    5,  979,    0,    3,    0,    7,    9,    3],\n",
      "       [   0,    3,    5,    0,  941,    0,    3,    2,    1,   25],\n",
      "       [   6,    0,    2,   28,    3,  828,    8,    2,    8,    5],\n",
      "       [   6,    3,    0,    1,    8,   13,  915,    0,    9,    1],\n",
      "       [   1,    3,   12,    5,    3,    1,    0,  988,    2,   12],\n",
      "       [   4,    0,    3,   10,    9,    7,    0,    1,  932,    7],\n",
      "       [   2,    3,    0,    8,   14,    0,    0,    7,   13,  961]],\n",
      "      dtype=int64)}\n",
      "Epoch 1: loss=0.49740\n",
      "Epoch 2: loss=0.25746\n",
      "Epoch 3: loss=0.20579\n",
      "Epoch 4: loss=0.16402\n",
      "Epoch 5: loss=0.14261\n",
      "Epoch 6: loss=0.13027\n",
      "Epoch 7: loss=0.12596\n",
      "Epoch 8: loss=0.11476\n",
      "Epoch 9: loss=0.10688\n",
      "Epoch 10: loss=0.11002\n",
      "Epoch 11: loss=0.10437\n",
      "Epoch 12: loss=0.10838\n",
      "Epoch 13: loss=0.10326\n",
      "Epoch 14: loss=0.10664\n",
      "Epoch 15: loss=0.11348\n",
      "Epoch 16: loss=0.09177\n",
      "Epoch 17: loss=0.09107\n",
      "Epoch 18: loss=0.10499\n",
      "Epoch 19: loss=0.09908\n",
      "Epoch 20: loss=0.09868\n",
      "Epoch 21: loss=0.10378\n",
      "Epoch 22: loss=0.10627\n",
      "Epoch 23: loss=0.10090\n",
      "Epoch 24: loss=0.10309\n",
      "Epoch 25: loss=0.09513\n",
      "Epoch 26: loss=0.09962\n",
      "Epoch 27: loss=0.09243\n",
      "Epoch 28: loss=0.08832\n",
      "Epoch 29: loss=0.09277\n",
      "Epoch 30: loss=0.08680\n",
      "Model 2: {'accuracy': 0.9637419871794872, 'precision': 0.964088739537627, 'recall': 0.9631815350890636, 'f1': 0.9634190817312037, 'confusion_matrix': array([[ 959,    0,    3,    1,    1,    2,    6,    3,    3,    1],\n",
      "       [   0, 1118,    4,    2,    0,    1,    3,    1,    4,    0],\n",
      "       [   3,    2,  998,   11,    2,    0,    3,    5,    5,    1],\n",
      "       [   0,    1,    6,  988,    0,    8,    0,    3,    2,    0],\n",
      "       [   0,    0,    6,    0,  949,    1,    5,    1,    1,   17],\n",
      "       [   2,    0,    2,   30,    3,  832,   10,    0,    5,    6],\n",
      "       [   4,    1,    0,    0,    5,    6,  935,    1,    4,    0],\n",
      "       [   1,    7,   23,    9,    2,    1,    1,  971,    2,   10],\n",
      "       [   4,    1,    2,   30,    7,    6,    4,    3,  912,    4],\n",
      "       [   0,    4,    1,   13,   16,    2,    1,    7,    4,  960]],\n",
      "      dtype=int64)}\n",
      "Epoch 1: loss=1.37645\n",
      "Epoch 2: loss=1.06917\n",
      "Epoch 3: loss=0.89540\n",
      "Epoch 4: loss=0.72533\n",
      "Epoch 5: loss=0.67451\n",
      "Epoch 6: loss=0.62499\n",
      "Epoch 7: loss=0.51443\n",
      "Epoch 8: loss=0.38278\n",
      "Epoch 9: loss=0.36821\n",
      "Epoch 10: loss=0.33830\n",
      "Epoch 11: loss=0.33287\n",
      "Epoch 12: loss=0.29771\n",
      "Epoch 13: loss=0.26131\n",
      "Epoch 14: loss=0.28290\n",
      "Epoch 15: loss=0.26069\n",
      "Epoch 16: loss=0.25541\n",
      "Epoch 17: loss=0.24444\n",
      "Epoch 18: loss=0.24528\n",
      "Epoch 19: loss=0.25002\n",
      "Epoch 20: loss=0.25842\n",
      "Epoch 21: loss=0.24128\n",
      "Epoch 22: loss=0.23112\n",
      "Epoch 23: loss=0.22898\n",
      "Epoch 24: loss=0.23274\n",
      "Epoch 25: loss=0.22021\n",
      "Epoch 26: loss=0.22365\n",
      "Epoch 27: loss=0.26753\n",
      "Epoch 28: loss=0.23407\n",
      "Epoch 29: loss=0.26736\n",
      "Epoch 30: loss=0.25502\n",
      "Model 3: {'accuracy': 0.9203725961538461, 'precision': 0.9231505684304151, 'recall': 0.9198507547830644, 'f1': 0.9202792012122571, 'confusion_matrix': array([[ 925,    0,    7,    2,    0,    7,   14,    2,    7,   15],\n",
      "       [   0, 1094,    3,    4,    0,    3,    8,    4,   15,    2],\n",
      "       [  12,    1,  972,   11,    0,    3,    2,   11,    9,    9],\n",
      "       [   6,    1,   17,  889,    0,   47,    0,    9,   23,   16],\n",
      "       [   1,    1,    6,    0,  825,    1,   16,    0,    6,  124],\n",
      "       [   4,    0,    0,   12,    0,  830,    7,    1,   14,   22],\n",
      "       [   6,    2,    4,    1,    6,   15,  894,    0,    8,   20],\n",
      "       [   2,    7,   25,    4,    1,    3,    1,  944,    5,   35],\n",
      "       [   2,    2,   14,    5,    2,   18,   10,    2,  900,   18],\n",
      "       [   7,   10,    3,    7,   17,   12,    0,   18,   18,  916]],\n",
      "      dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "print('Running benchmark on MNIST dataset')\n",
    "\n",
    "# Array for statistics of each model\n",
    "mnist_stats = []\n",
    "\n",
    "# Run each model\n",
    "for i, model in enumerate(models_mnist):\n",
    "    model.train(mnist_x_train, mnist_y_train, 256, num_epochs=30)\n",
    "    accuracy, precision, recall, f1, confusion_matrix = get_metrics(mnist_x_test, mnist_y_test, 256, model)\n",
    "    stats = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': confusion_matrix\n",
    "    }\n",
    "\n",
    "    print(f'Model {i+1}: {stats}')\n",
    "    mnist_stats.append(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11.6%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "35.2%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "58.1%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "82.8%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n",
      "100.6%\n",
      "43.1%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "119.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to cached_datasets\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Extracting cached_datasets\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to cached_datasets\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to cached_datasets\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting cached_datasets\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to cached_datasets\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to cached_datasets\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Extracting cached_datasets\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to cached_datasets\\FashionMNIST\\raw\n",
      "\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-46-65e571d3828c>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[0mi\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodels_fashion_mnist\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 27\u001B[1;33m     \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmnist_x_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmnist_y_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m256\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m30\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m# train the model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     28\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m     \u001B[1;31m# Get metrics\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-41-b703da7e7eb2>\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(self, x_data, y_data, batch_size, num_steps, time_step, lr, num_epochs)\u001B[0m\n\u001B[0;32m    210\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    211\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_recurrent\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# if the network does not contain recurrent weights run it as feedforward\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 212\u001B[1;33m                     output, spike_recs, layer_outputs, mem_recs = self.run_feed_forward(x_local.to_dense(), batch_size,\n\u001B[0m\u001B[0;32m    213\u001B[0m                                                                                         num_steps)\n\u001B[0;32m    214\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-41-b703da7e7eb2>\u001B[0m in \u001B[0;36mrun_feed_forward\u001B[1;34m(self, inputs, batch_size, steps, spike_fn)\u001B[0m\n\u001B[0;32m    150\u001B[0m                 \u001B[0mspike_out\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mspike_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmem_threshold\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    151\u001B[0m                 \u001B[0mrst\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzeros_like\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmem_hidden_i\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 152\u001B[1;33m                 \u001B[0mc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mmem_threshold\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    153\u001B[0m                 \u001B[0mrst\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mc\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mones_like\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmem_hidden_i\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mc\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    154\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Fashion MNIST\n",
    "train_dataset = torchvision.datasets.FashionMNIST(dataset_folder, train=True,\n",
    "                                           transform=None, target_transform=None, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(dataset_folder, train=False,\n",
    "                                          transform=None, target_transform=None, download=True)\n",
    "\n",
    "# Create the same models for the Fashion MNIST dataset\n",
    "models_fashion_mnist = [\n",
    "    DeepSNNModel([28*28, 256, 128, 10]),\n",
    "    DeepSNNModel([28*28, 256, 128, 64, 10]),\n",
    "    DeepSNNModel([28*28, 256, 128, 10], recurrent=True),\n",
    "    DeepSNNModel([28*28, 256, 128, 64, 10], recurrent=True)\n",
    "]\n",
    "\n",
    "# Standardize the data\n",
    "fmnist_x_train = np.array(train_dataset.data, dtype=np.float)\n",
    "fmnist_x_train = fmnist_x_train.reshape(fmnist_x_train.shape[0], -1) / 255\n",
    "fmnist_x_test = np.array(test_dataset.data, dtype=np.float)\n",
    "fmnist_x_test = fmnist_x_test.reshape(fmnist_x_test.shape[0], -1) / 255\n",
    "\n",
    "fmnist_y_train = np.array(train_dataset.targets, dtype=np.int)\n",
    "fmnist_y_test = np.array(test_dataset.targets, dtype=np.int)\n",
    "\n",
    "fashion_mnist_stats = []\n",
    "i = 1\n",
    "for i, model in enumerate(models_fashion_mnist):\n",
    "    model.train(mnist_x_train, mnist_y_train, 256, num_epochs=30) # train the model\n",
    "\n",
    "    # Get metrics\n",
    "    accuracy, precision, recall, f1, confusion_matrix = get_metrics(mnist_x_test, mnist_y_test, 256, model)\n",
    "\n",
    "    # Create dictionary for later use\n",
    "    stats = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': confusion_matrix\n",
    "    }\n",
    "\n",
    "    # Print and save the stats\n",
    "    print(f'Model {i+1}: {stats}')\n",
    "    fashion_mnist_stats.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "  model  accuracy  precision    recall        f1\n0     1  0.969752   0.969747  0.969537  0.969496\n1     2  0.963742   0.963730  0.963078  0.963299\n2     3  0.963742   0.964089  0.963182  0.963419\n3     4  0.920373   0.923151  0.919851  0.920279",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.969752</td>\n      <td>0.969747</td>\n      <td>0.969537</td>\n      <td>0.969496</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.963742</td>\n      <td>0.963730</td>\n      <td>0.963078</td>\n      <td>0.963299</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.963742</td>\n      <td>0.964089</td>\n      <td>0.963182</td>\n      <td>0.963419</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.920373</td>\n      <td>0.923151</td>\n      <td>0.919851</td>\n      <td>0.920279</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_df = pd.DataFrame({\n",
    "    'model': [f'{i}' for i in range(1, len(models_mnist) + 1)],\n",
    "    'accuracy': [x['accuracy'] for x in mnist_stats],\n",
    "    'precision': [x['precision'] for x in mnist_stats],\n",
    "    'recall': [x['recall'] for x in mnist_stats],\n",
    "    'f1': [x['f1'] for x in mnist_stats],\n",
    "})\n",
    "\n",
    "mnist_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrices:\n",
      "[[ 972    0    0    2    0    0    1    0    2    2]\n",
      " [   3 1115    3    1    2    1    4    1    3    0]\n",
      " [  10    0  991    5    3    0    1    6   13    1]\n",
      " [   1    0    7  975    0    7    0    7   10    1]\n",
      " [   0    0    1    0  969    0    3    1    1    5]\n",
      " [   4    0    0   17    1  847    9    2    9    1]\n",
      " [   9    2    0    0    4    2  937    1    1    0]\n",
      " [   3    8    6    3    1    0    1  989    8    8]\n",
      " [  12    1    2    3    6    2    4    2  936    5]\n",
      " [  10    3    0    5   25    4    0    3    7  951]]\n",
      "[[ 968    0    0    0    1    0    2    1    5    2]\n",
      " [   1 1118    3    1    0    0    3    1    6    0]\n",
      " [   5    1  992    8    2    0    3    8    9    2]\n",
      " [   1    1    5  979    0    3    0    7    9    3]\n",
      " [   0    3    5    0  941    0    3    2    1   25]\n",
      " [   6    0    2   28    3  828    8    2    8    5]\n",
      " [   6    3    0    1    8   13  915    0    9    1]\n",
      " [   1    3   12    5    3    1    0  988    2   12]\n",
      " [   4    0    3   10    9    7    0    1  932    7]\n",
      " [   2    3    0    8   14    0    0    7   13  961]]\n",
      "[[ 959    0    3    1    1    2    6    3    3    1]\n",
      " [   0 1118    4    2    0    1    3    1    4    0]\n",
      " [   3    2  998   11    2    0    3    5    5    1]\n",
      " [   0    1    6  988    0    8    0    3    2    0]\n",
      " [   0    0    6    0  949    1    5    1    1   17]\n",
      " [   2    0    2   30    3  832   10    0    5    6]\n",
      " [   4    1    0    0    5    6  935    1    4    0]\n",
      " [   1    7   23    9    2    1    1  971    2   10]\n",
      " [   4    1    2   30    7    6    4    3  912    4]\n",
      " [   0    4    1   13   16    2    1    7    4  960]]\n",
      "[[ 925    0    7    2    0    7   14    2    7   15]\n",
      " [   0 1094    3    4    0    3    8    4   15    2]\n",
      " [  12    1  972   11    0    3    2   11    9    9]\n",
      " [   6    1   17  889    0   47    0    9   23   16]\n",
      " [   1    1    6    0  825    1   16    0    6  124]\n",
      " [   4    0    0   12    0  830    7    1   14   22]\n",
      " [   6    2    4    1    6   15  894    0    8   20]\n",
      " [   2    7   25    4    1    3    1  944    5   35]\n",
      " [   2    2   14    5    2   18   10    2  900   18]\n",
      " [   7   10    3    7   17   12    0   18   18  916]]\n"
     ]
    }
   ],
   "source": [
    "# Print confusion matrix for each model\n",
    "print('Confusion Matrices:')\n",
    "for confusion_matrix in map(lambda x: x['confusion_matrix'], mnist_stats):\n",
    "    print(confusion_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# Create output directory to save the results\n",
    "output_path = 'results'\n",
    "os.makedirs(output_path, exist_ok=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# Save as XLSX (excel) file\n",
    "mnist_df.to_excel(os.path.join(output_path, 'mnist_results.xlsx'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fmnist_df = pd.DataFrame({\n",
    "    'model': [f'{i}' for i in range(1, len(models_fashion_mnist))],\n",
    "    'accuracy': [x['accuracy'] for x in fashion_mnist_stats],\n",
    "    'precision': [x['precision'] for x in fashion_mnist_stats],\n",
    "    'recall': [x['recall'] for x in fashion_mnist_stats],\n",
    "    'f1': [x['f1'] for x in fashion_mnist_stats],\n",
    "})\n",
    "\n",
    "fmnist_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Print confusion matrix for each model\n",
    "print('Confusion Matrices:')\n",
    "for confusion_matrix in map(lambda x: x['confusion_matrix'], fashion_mnist_stats):\n",
    "    print(confusion_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save as XLSX\n",
    "fmnist_df.to_excel(os.path.join(output_path, 'fashion_mnist_results.xlsx'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}