{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import os\n",
    "import nengo\n",
    "import nengo_dl\n",
    "import numpy as np\n",
    "import keras\n",
    "import sklearn.model_selection\n",
    "import tensorflow as tf\n",
    "import snntoolbox.bin.run\n",
    "from snntoolbox.utils.utils import import_configparser\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import Conv2D, BatchNormalization, Dropout, AveragePooling2D, Flatten, Dense"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "os.makedirs('params', exist_ok=True)\n",
    "dataset_path = os.path.join('..', 'datasets', 'output', 'p300-target-nontarget.npz')\n",
    "nengo_keras_params_path = os.path.join('params', 'nengo_keras_params')\n",
    "model_name = 'keras_snn_toolbox'\n",
    "snn_toolbox_model_output = os.path.join('params', model_name)\n",
    "snn_toolbox_config_path = os.path.join('params', 'snn_config')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(file):\n",
    "    dataset = np.load(file)\n",
    "    target_x, non_target_x = dataset['target_features'], dataset['non_target_features']\n",
    "\n",
    "    if target_x.shape[0] > non_target_x.shape[0]:\n",
    "        target_x = target_x[:non_target_x.shape[0]]\n",
    "    else:\n",
    "        non_target_x = non_target_x[:target_x.shape[0]]\n",
    "\n",
    "    # (1,0) for target data, (0,1) for non target data\n",
    "    target_y = np.tile(np.array([1, 0]), (target_x.shape[0], 1))\n",
    "    non_target_y = np.tile(np.array([0, 1]), (non_target_x.shape[0], 1))\n",
    "\n",
    "    features = np.concatenate((target_x, non_target_x), axis=0)\n",
    "    labels = np.concatenate((target_y, non_target_y), axis=0)\n",
    "\n",
    "    features = np.expand_dims(features, -1)\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def create_nn():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=6, kernel_size=(3, 3), activation=keras.activations.elu, input_shape=(3, 1201, 1),\n",
    "                     name='input_layer'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5, seed=0))\n",
    "    model.add(AveragePooling2D(pool_size=(1, 8)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation=keras.activations.elu))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5, seed=0))\n",
    "    model.add(Dense(2, activation=keras.activations.softmax, name='output_layer'))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def run_vanilla_tensorflow(train_x, train_y, valid_x, valid_y, test_x, test_y, test_results):\n",
    "    vanilla_tensorflow_model = create_nn()\n",
    "    vanilla_tensorflow_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    vanilla_tensorflow_model.fit(\n",
    "        x=train_x,\n",
    "        y=train_y,\n",
    "        shuffle=True,\n",
    "        epochs=30,\n",
    "        batch_size=16,\n",
    "        callbacks=[keras.callbacks.EarlyStopping(patience=5, verbose=1, restore_best_weights=1)],\n",
    "        validation_data=(valid_x, valid_y)\n",
    "    )\n",
    "\n",
    "    eval = vanilla_tensorflow_model.evaluate(test_x, test_y)\n",
    "\n",
    "    test_results.append(eval)\n",
    "    return vanilla_tensorflow_model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% run w/ snn toolbox\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# jina verze tensorflow?\n",
    "\n",
    "def run_spiking_network(activation, model: tf.keras.Model, ann_params, snn_results, test_x, test_y, scale_firing_rates=1,\n",
    "                        synapse=None, n_steps=30):\n",
    "    converter = nengo_dl.Converter(\n",
    "        model,\n",
    "        swap_activations={tf.nn.elu: activation},\n",
    "        scale_firing_rates=scale_firing_rates,\n",
    "        synapse=synapse\n",
    "    )\n",
    "\n",
    "    input_layer, output_layer = model.get_layer('input_layer'), model.get_layer('output_layer')\n",
    "    nengo_input, nengo_output = converter.inputs[input_layer], converter.outputs[output_layer]\n",
    "\n",
    "    tiled_data = np.tile(test_x, (1, n_steps, 1))\n",
    "\n",
    "    with converter.net:\n",
    "        nengo_dl.configure_settings(stateful=False)\n",
    "\n",
    "    with nengo_dl.Simulator(converter.net, minibatch_size=16, progress_bar=False) as sim:\n",
    "        sim.load_params(ann_params)\n",
    "        data = sim.predict(tiled_data)\n",
    "\n",
    "    predictions = np.argmax(data[nengo_output][:, -1], axis=-1)\n",
    "    accuracy = (predictions == test_y).mean()\n",
    "    print('accuracy: {:4f}%'.format(accuracy*100))\n",
    "    snn_results.append(accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Does not work\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def run_nengo_model(train_x, train_y, valid_x, valid_y, test_x, test_y, test_results, snn_results):\n",
    "    model = create_nn()\n",
    "    converter = nengo_dl.Converter(model)\n",
    "\n",
    "    with nengo_dl.Simulator(converter.net, minibatch_size=16) as sim:\n",
    "        sim.compile(\n",
    "            optimizer=tf.optimizers.Adam(),\n",
    "            loss=tf.losses.BinaryCrossentropy(),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        sim.fit(\n",
    "            x=train_x,\n",
    "            y=train_y,\n",
    "            shuffle=True,\n",
    "            epochs=30,\n",
    "            callbacks=[keras.callbacks.EarlyStopping(patience=5, verbose=1, restore_best_weights=1)],\n",
    "            validation_data=(valid_x, valid_y)\n",
    "        )\n",
    "\n",
    "        eval = sim.evaluate(test_x, test_y)\n",
    "\n",
    "        test_results.append(eval)\n",
    "\n",
    "        sim.save_params(nengo_keras_params_path)\n",
    "\n",
    "    run_spiking_network(\n",
    "        activation=nengo.SpikingRectifiedLinear(),\n",
    "        model=model,\n",
    "        ann_params=nengo_keras_params_path,\n",
    "        test_x=test_x,\n",
    "        test_y=test_y,\n",
    "        synapse=0.01,\n",
    "        snn_results=snn_results\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Does not work\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def run_snn_toolbox(snn_results, config_file_path):\n",
    "    return snn_results.append(snntoolbox.bin.run.main(config_file_path))\n",
    "\n",
    "def snn_config(model_path, dataset_path, model_name, test_count):\n",
    "    config_parser = import_configparser()\n",
    "    config = config_parser.ConfigParser()\n",
    "\n",
    "    config['paths'] = {\n",
    "        'path_wd': model_path,\n",
    "        'dataset_path': dataset_path,\n",
    "        'filename_ann': model_name\n",
    "    }\n",
    "\n",
    "    config['tools'] = {\n",
    "      'evaluate_ann': False,\n",
    "      'normalize': True\n",
    "  }\n",
    "\n",
    "    config['simulation'] = {\n",
    "        'simulator': 'INI',\n",
    "        'duration': 50,\n",
    "        'num_to_test': test_count,\n",
    "        'batch_size': 10\n",
    "    }\n",
    "    return config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "(3050, 3, 1201, 1) (3050, 2)\n",
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Construction finished in 0:00:00                                               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\itznu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\nengo_dl\\converter.py:932: UserWarning: Converting sequential model to functional model; use `Converter.model` to refer to the functional model (rather than the original sequential model) when working with the output of the Converter\n",
      "  warnings.warn(\n",
      "c:\\users\\itznu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\nengo_dl\\converter.py:589: UserWarning: Activation type <function elu at 0x000001A8F20FBF70> does not have a native Nengo equivalent; falling back to a TensorNode\n",
      "  warnings.warn(\n",
      "c:\\users\\itznu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\nengo_dl\\converter.py:325: UserWarning: Cannot convert BatchNormalization layer to native Nengo objects unless inference_only=True or layer.trainable=False. Falling back to TensorNode.\n",
      "  warnings.warn(\n",
      "c:\\users\\itznu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\nengo_dl\\converter.py:325: UserWarning: Layer type <class 'tensorflow.python.keras.layers.core.Dropout'> does not have a registered converter. Falling back to TensorNode.\n",
      "  warnings.warn(\n",
      "c:\\users\\itznu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\nengo_dl\\converter.py:589: UserWarning: Activation type <function softmax at 0x000001A8F20FBE50> does not have a native Nengo equivalent; falling back to a TensorNode\n",
      "  warnings.warn(\n",
      "c:\\users\\itznu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\nengo_dl\\simulator.py:1771: UserWarning: Number of elements (1) in ['ndarray'] does not match number of Nodes (4); consider using an explicit input dictionary in this case, so that the assignment of data to objects is unambiguous.\n",
      "  warnings.warn(\n",
      "c:\\users\\itznu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\nengo_dl\\simulator.py:1931: UserWarning: Number of elements in input data (1715) is not evenly divisible by Simulator.minibatch_size (16); input data will be truncated.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "input_6 data: should have rank 3 (batch_size, n_steps, dimensions), found rank 4",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-19-43477076d185>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     35\u001B[0m     \u001B[0mcurrent_valid_y\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_y\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mvalid\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 37\u001B[1;33m     run_nengo_model(\n\u001B[0m\u001B[0;32m     38\u001B[0m         \u001B[0mtrain_x\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcurrent_train_x\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     39\u001B[0m         \u001B[0mtrain_y\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcurrent_train_y\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-17-6f4dc7fc4b85>\u001B[0m in \u001B[0;36mrun_nengo_model\u001B[1;34m(train_x, train_y, valid_x, valid_y, test_x, test_y, test_results, snn_results)\u001B[0m\n\u001B[0;32m     10\u001B[0m         )\n\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m         sim.fit(\n\u001B[0m\u001B[0;32m     13\u001B[0m             \u001B[0mx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrain_x\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m             \u001B[0my\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrain_y\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\itznu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\nengo\\utils\\magic.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    179\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwrapped\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minstance\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    180\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 181\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__wrapped__\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minstance\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    182\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    183\u001B[0m             \u001B[0minstance\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__wrapped__\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"__self__\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\itznu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\nengo_dl\\simulator.py\u001B[0m in \u001B[0;36mrequire_open\u001B[1;34m(wrapped, instance, args, kwargs)\u001B[0m\n\u001B[0;32m     73\u001B[0m         )\n\u001B[0;32m     74\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 75\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mwrapped\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     76\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\itznu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\nengo_dl\\simulator.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, n_steps, stateful, **kwargs)\u001B[0m\n\u001B[0;32m    861\u001B[0m             \u001B[0mx_val\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    862\u001B[0m             \u001B[0mx_val\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_generate_inputs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_val\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_steps\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mn_steps\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 863\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_check_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_val\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_steps\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mn_steps\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    864\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    865\u001B[0m             \u001B[0my_val\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\itznu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\nengo_dl\\simulator.py\u001B[0m in \u001B[0;36m_check_data\u001B[1;34m(self, data, batch_size, n_steps, nodes)\u001B[0m\n\u001B[0;32m   1966\u001B[0m             \u001B[1;31m# generic shape checks\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1967\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1968\u001B[1;33m                 raise ValidationError(\n\u001B[0m\u001B[0;32m   1969\u001B[0m                     \u001B[1;34m\"should have rank 3 (batch_size, n_steps, dimensions), \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1970\u001B[0m                     \u001B[1;34m\"found rank %d\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValidationError\u001B[0m: input_6 data: should have rank 3 (batch_size, n_steps, dimensions), found rank 4"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "features, labels = get_dataset(dataset_path)\n",
    "print(features.shape, labels.shape)\n",
    "\n",
    "test_results, snn_results = [], []\n",
    "\n",
    "train_x, test_x, train_y, test_y = sklearn.model_selection.train_test_split(\n",
    "    features, labels, test_size=0.25, random_state=seed, shuffle=True\n",
    ")\n",
    "\n",
    "len(train_x)\n",
    "\n",
    "np.savez_compressed(os.path.join('params','x_test'), test_x)\n",
    "np.savez_compressed(os.path.join('params','y_test'), test_y)\n",
    "np.savez_compressed(os.path.join('params','x_norm'), train_x[::10])\n",
    "\n",
    "config = snn_config(\n",
    "    model_path=os.path.join('params'),\n",
    "    dataset_path=os.path.join('params'),\n",
    "    model_name=model_name,\n",
    "    test_count=test_x.shape[0]\n",
    ")\n",
    "with open(snn_toolbox_config_path, 'w') as file:\n",
    "    config.write(file)\n",
    "\n",
    "shuffle_split = sklearn.model_selection.ShuffleSplit(n_splits=5, test_size=0.25, random_state=seed)\n",
    "\n",
    "for train, valid in shuffle_split.split(train_x):\n",
    "    current_train_x = train_x[train]\n",
    "    current_train_y = train_y[train]\n",
    "    current_valid_x = train_x[valid]\n",
    "    current_valid_y = train_y[valid]\n",
    "\n",
    "    run_nengo_model(\n",
    "        train_x=current_train_x,\n",
    "        train_y=current_train_y,\n",
    "        valid_x=current_train_x,\n",
    "        valid_y=current_valid_y,\n",
    "        test_x=test_x,\n",
    "        test_y=test_y,\n",
    "        test_results=test_results,\n",
    "        snn_results=snn_results\n",
    "    )\n",
    "\n",
    "    # model = run_vanilla_tensorflow(\n",
    "    #     train_x=current_train_x,\n",
    "    #     train_y=current_train_y,\n",
    "    #     valid_x=current_valid_x,\n",
    "    #     valid_y=current_valid_y,\n",
    "    #     test_x=test_x,\n",
    "    #     test_y=test_y,\n",
    "    #     test_results=test_results\n",
    "    # )\n",
    "    # model.save(snn_toolbox_model_output + '.h5')\n",
    "    #\n",
    "    # run_snn_toolbox(snn_results, config_file_path=snn_toolbox_config_path)\n",
    "\n",
    "\n",
    "for i in range(len(test_results)):\n",
    "    print('ANN acc: {}, SNN acc: {}'.format(test_results[i][1], snn_results[i]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(test_results, snn_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}