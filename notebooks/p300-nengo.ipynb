{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nengo\n",
    "import nengo_dl\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import sklearn.model_selection\n",
    "from tensorflow.python.keras import Model, Sequential, Input\n",
    "from tensorflow.python.keras.layers import Conv2D, BatchNormalization, Dropout, AveragePooling2D, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_x: (1525, 3, 1201) non_target_x: (1525, 3, 1201)\n",
      "target_y: [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " ...\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]] non_target_y: [[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n",
      "[[[[-8.04011680e-06]\n",
      "   [-8.70710899e-06]\n",
      "   [-8.82429649e-06]\n",
      "   ...\n",
      "   [-4.60801559e-05]\n",
      "   [-4.59580855e-05]\n",
      "   [-4.65410934e-05]]\n",
      "\n",
      "  [[-1.91131598e-05]\n",
      "   [-1.98250738e-05]\n",
      "   [-1.99373785e-05]\n",
      "   ...\n",
      "   [-5.13797613e-05]\n",
      "   [-5.14608160e-05]\n",
      "   [-5.21395270e-05]]\n",
      "\n",
      "  [[-1.35353725e-05]\n",
      "   [-1.47272670e-05]\n",
      "   [-1.53405482e-05]\n",
      "   ...\n",
      "   [-4.72189662e-05]\n",
      "   [-4.79357631e-05]\n",
      "   [-4.91300990e-05]]]\n",
      "\n",
      "\n",
      " [[[ 7.30717020e-06]\n",
      "   [ 8.66459208e-06]\n",
      "   [ 9.64115458e-06]\n",
      "   ...\n",
      "   [-3.21293532e-05]\n",
      "   [-3.20863845e-05]\n",
      "   [-3.22665603e-05]]\n",
      "\n",
      "  [[ 6.92052433e-07]\n",
      "   [ 2.11197431e-06]\n",
      "   [ 3.23892743e-06]\n",
      "   ...\n",
      "   [-3.16458382e-05]\n",
      "   [-3.16995491e-05]\n",
      "   [-3.20110726e-05]]\n",
      "\n",
      "  [[ 8.42213250e-06]\n",
      "   [ 9.38160516e-06]\n",
      "   [ 9.87623406e-06]\n",
      "   ...\n",
      "   [-5.55348987e-05]\n",
      "   [-5.55178089e-05]\n",
      "   [-5.56154652e-05]]]\n",
      "\n",
      "\n",
      " [[[-3.07758085e-06]\n",
      "   [-3.97748319e-06]\n",
      "   [-4.96820585e-06]\n",
      "   ...\n",
      "   [-3.03280691e-05]\n",
      "   [-2.96908621e-05]\n",
      "   [-2.90805105e-05]]\n",
      "\n",
      "  [[-1.57444078e-05]\n",
      "   [-1.65334703e-05]\n",
      "   [-1.73293688e-05]\n",
      "   ...\n",
      "   [-4.57297594e-05]\n",
      "   [-4.51350328e-05]\n",
      "   [-4.44514391e-05]]\n",
      "\n",
      "  [[-1.11134562e-05]\n",
      "   [-1.10797648e-05]\n",
      "   [-1.10529093e-05]\n",
      "   ...\n",
      "   [-4.10499796e-05]\n",
      "   [-4.04259562e-05]\n",
      "   [-3.97355265e-05]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-4.32359564e-06]\n",
      "   [-5.23143256e-06]\n",
      "   [-6.16380561e-06]\n",
      "   ...\n",
      "   [-3.16581904e-05]\n",
      "   [-3.12446162e-05]\n",
      "   [-3.07609736e-05]]\n",
      "\n",
      "  [[-4.75214990e-06]\n",
      "   [-5.59297021e-06]\n",
      "   [-6.45185693e-06]\n",
      "   ...\n",
      "   [-2.09250015e-05]\n",
      "   [-2.03527358e-05]\n",
      "   [-1.96859878e-05]]\n",
      "\n",
      "  [[-8.44756533e-06]\n",
      "   [-9.25628116e-06]\n",
      "   [-1.00207465e-05]\n",
      "   ...\n",
      "   [-7.87536075e-06]\n",
      "   [-7.30163028e-06]\n",
      "   [-6.75841739e-06]]]\n",
      "\n",
      "\n",
      " [[[-4.43766762e-06]\n",
      "   [-3.97685219e-06]\n",
      "   [-3.12382485e-06]\n",
      "   ...\n",
      "   [-2.86472623e-05]\n",
      "   [-2.78141325e-05]\n",
      "   [-2.72129362e-05]]\n",
      "\n",
      "  [[-6.82924732e-06]\n",
      "   [-5.91371997e-06]\n",
      "   [-4.49770435e-06]\n",
      "   ...\n",
      "   [-3.23099602e-05]\n",
      "   [-3.14005364e-05]\n",
      "   [-3.08482903e-05]]\n",
      "\n",
      "  [[-5.10623609e-06]\n",
      "   [-4.52945387e-06]\n",
      "   [-3.46591627e-06]\n",
      "   ...\n",
      "   [-2.93570295e-05]\n",
      "   [-2.85925642e-05]\n",
      "   [-2.82599226e-05]]]\n",
      "\n",
      "\n",
      " [[[ 1.79280477e-06]\n",
      "   [ 4.33307705e-07]\n",
      "   [-6.83635655e-07]\n",
      "   ...\n",
      "   [-4.62449150e-05]\n",
      "   [-4.67362480e-05]\n",
      "   [-4.71863212e-05]]\n",
      "\n",
      "  [[ 3.08220859e-06]\n",
      "   [ 1.06975741e-06]\n",
      "   [-7.56658602e-07]\n",
      "   ...\n",
      "   [-5.56563168e-05]\n",
      "   [-5.64802914e-05]\n",
      "   [-5.72219906e-05]]\n",
      "\n",
      "  [[ 7.24756042e-06]\n",
      "   [ 4.27209655e-06]\n",
      "   [ 1.58197204e-06]\n",
      "   ...\n",
      "   [-6.05487653e-05]\n",
      "   [-6.21936627e-05]\n",
      "   [-6.38095685e-05]]]] [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "dataset = np.load(file=os.path.join('..', 'datasets', 'output', 'p300-target-nontarget.npz'))\n",
    "target_x, non_target_x = dataset['target_features'], dataset['non_target_features']\n",
    "\n",
    "# trim target or non target data to have same amount of samples\n",
    "if target_x.shape[0] > non_target_x.shape[0]:\n",
    "    target_x = target_x[:non_target_x.shape[0]]\n",
    "else:\n",
    "    non_target_x = non_target_x[:target_x.shape[0]]\n",
    "\n",
    "print('target_x:', target_x.shape, 'non_target_x:', non_target_x.shape)\n",
    "\n",
    "# (1, 0) vector for target data\n",
    "target_y = np.tile(np.array([1, 0]), (target_x.shape[0], 1))\n",
    "# (0, 1) vector for non target data\n",
    "non_target_y = np.tile(np.array([0, 1]), (non_target_x.shape[0], 1))\n",
    "print('target_y:', target_y, 'non_target_y:', non_target_y)\n",
    "\n",
    "features = np.concatenate((target_x, non_target_x), axis=0)\n",
    "labels = np.vstack((target_y, non_target_y))\n",
    "features = np.expand_dims(features, -1)\n",
    "print(features, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# global seed for consistency\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def create_nn():\n",
    "    input_layer = Input(shape=(3, 1201, 1))\n",
    "    conv_input = Conv2D(filters=6, kernel_size=(3, 3), activation=tf.nn.elu)(input_layer)\n",
    "    batch_norm1 = BatchNormalization()(conv_input)\n",
    "    dropout1 = Dropout(0.5)(batch_norm1)\n",
    "    avg_pooling = AveragePooling2D(pool_size=(1, 8))(dropout1)\n",
    "    flatten = Flatten()(avg_pooling)\n",
    "    dense1 = Dense(100, activation=keras.activations.elu)(flatten)\n",
    "    batch_norm2 = BatchNormalization()(dense1)\n",
    "    dropout2 = Dropout(0.5)(batch_norm2)\n",
    "    output_layer = Dense(2, activation=keras.activations.softmax)(dropout2)\n",
    "\n",
    "    return Model(inputs=input_layer, outputs=output_layer), input_layer, output_layer\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def run_spiking(\n",
    "        model, input_layer, output_layer, activation, test_data_x, test_data_y, params_file='keras_to_snn_params',\n",
    "        scale_firing_rates=1, synapse=None\n",
    "):\n",
    "    converter = nengo_dl.Converter(model, swap_activations={ tf.nn.elu: activation },\n",
    "                                   scale_firing_rates=scale_firing_rates, synapse=synapse)\n",
    "\n",
    "    nengo_input, nengo_output = converter.inputs[input_layer], converter.inputs[output_layer]\n",
    "\n",
    "    with nengo_dl.Simulator(converter.net, minibatch_size=10, progress_bar=False) as nengo_sim:\n",
    "        nengo_sim.load_params(params_file)\n",
    "        data = nengo_sim.predict({ nengo_input: test_data_x })\n",
    "\n",
    "    predictions = np.argmax(data[nengo_output][:, -1], axis=-1)\n",
    "    acc = (predictions == test_data_y[:, 0, 0]).mean()\n",
    "    print('accuracy: {:4f}%'.format(acc*100))\n",
    "    return acc\n",
    "\n",
    "\n",
    "def run_model(\n",
    "        validation_metrics, test_metrics, snn_metrics,\n",
    "        train_x, train_y, validation_x, validation_y, test_x, test_y\n",
    "):\n",
    "    model, input_layer, output_layer = create_nn()\n",
    "\n",
    "    print('rank:', len(test_y.shape))\n",
    "\n",
    "    early_stop_callback = keras.callbacks.EarlyStopping(patience=5, verbose=1, restore_best_weights=True)\n",
    "\n",
    "    converter = nengo_dl.Converter(model)\n",
    "\n",
    "    with nengo_dl.Simulator(converter.net, minibatch_size=10) as sim:\n",
    "        sim.compile(\n",
    "            optimizer=tf.optimizers.Adam(),\n",
    "            loss=tf.losses.BinaryCrossentropy(),\n",
    "            metrics=[tf.metrics.binary_accuracy]\n",
    "        )\n",
    "\n",
    "        nengo_input, nengo_output = converter.inputs[input_layer], converter.outputs[output_layer]\n",
    "\n",
    "        hist = sim.fit(\n",
    "            { nengo_input: train_x },\n",
    "            { nengo_output: train_y },\n",
    "            callbacks=[early_stop_callback],\n",
    "            epochs=30,\n",
    "            batch_size=16,\n",
    "            shuffle=True,\n",
    "            validation_data=(\n",
    "                { nengo_input: validation_x },\n",
    "                { nengo_output: validation_y }\n",
    "            )\n",
    "        )\n",
    "        validation_metrics.append(hist)\n",
    "\n",
    "        acc, loss = sim.evaluate(test_x, test_y)\n",
    "        test_metrics.append((acc, loss))\n",
    "\n",
    "        sim.save_params('./keras_to_snn_params')\n",
    "        snn_acc = run_spiking(\n",
    "            model=model,\n",
    "            input_layer=input_layer,\n",
    "            output_layer=output_layer,\n",
    "            test_data_x=test_x, test_data_y=test_y,\n",
    "            scale_firing_rates=20,\n",
    "            activation=nengo.SpikingRectifiedLinear(),\n",
    "            synapse=.01\n",
    "        )\n",
    "        snn_metrics.append(snn_acc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank: 2\n",
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Construction finished in 0:00:00                                               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itznu\\anaconda3\\envs\\datascience-gpu\\lib\\site-packages\\nengo_dl\\converter.py:563: UserWarning: Activation type <function elu at 0x000001926233D0D8> does not have a native Nengo equivalent; falling back to a TensorNode\n",
      "  \"falling back to a TensorNode\" % activation\n",
      "C:\\Users\\itznu\\anaconda3\\envs\\datascience-gpu\\lib\\site-packages\\nengo_dl\\converter.py:309: UserWarning: Cannot convert BatchNormalization layer to native Nengo objects unless inference_only=True. Falling back to TensorNode.\n",
      "  % (error_msg + \". \" if error_msg else \"\")\n",
      "C:\\Users\\itznu\\anaconda3\\envs\\datascience-gpu\\lib\\site-packages\\nengo_dl\\converter.py:309: UserWarning: Layer type <class 'tensorflow.python.keras.layers.core.Dropout'> does not have a registered converter. Falling back to TensorNode.\n",
      "  % (error_msg + \". \" if error_msg else \"\")\n",
      "C:\\Users\\itznu\\anaconda3\\envs\\datascience-gpu\\lib\\site-packages\\nengo_dl\\converter.py:563: UserWarning: Activation type <function elu at 0x0000019264D00828> does not have a native Nengo equivalent; falling back to a TensorNode\n",
      "  \"falling back to a TensorNode\" % activation\n",
      "C:\\Users\\itznu\\anaconda3\\envs\\datascience-gpu\\lib\\site-packages\\nengo_dl\\converter.py:563: UserWarning: Activation type <function softmax at 0x0000019264D00708> does not have a native Nengo equivalent; falling back to a TensorNode\n",
      "  \"falling back to a TensorNode\" % activation\n",
      "C:\\Users\\itznu\\anaconda3\\envs\\datascience-gpu\\lib\\site-packages\\nengo_dl\\simulator.py:1932: UserWarning: Number of elements in input data (572) is not evenly divisible by Simulator.minibatch_size (10); input data will be truncated.\n",
      "  % (data_batch, self.minibatch_size)\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "input_4 data: should have rank 3 (batch_size, n_steps, dimensions), found rank 4",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-30-d85f1239d230>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     22\u001B[0m         \u001B[0mvalidation_y\u001B[0m\u001B[1;33m=\u001B[0m \u001B[0mtrain_y\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mvalidation\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m         \u001B[0mtest_x\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtest_x\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m         \u001B[0mtest_y\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtest_y\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m     )\n\u001B[0;32m     26\u001B[0m     \u001B[0miter\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-29-752a4a71b25f>\u001B[0m in \u001B[0;36mrun_model\u001B[1;34m(validation_metrics, test_metrics, snn_metrics, train_x, train_y, validation_x, validation_y, test_x, test_y)\u001B[0m\n\u001B[0;32m     46\u001B[0m             validation_data=(\n\u001B[0;32m     47\u001B[0m                 \u001B[1;33m{\u001B[0m \u001B[0mconverter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0minput_layer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mvalidation_x\u001B[0m \u001B[1;33m}\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 48\u001B[1;33m                 \u001B[1;33m{\u001B[0m \u001B[0mconverter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0moutput_layer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mtrain_y\u001B[0m \u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     49\u001B[0m             )\n\u001B[0;32m     50\u001B[0m         )\n",
      "\u001B[1;32m~\\anaconda3\\envs\\datascience-gpu\\lib\\site-packages\\nengo\\utils\\magic.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    179\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwrapped\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minstance\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    180\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 181\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__wrapped__\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minstance\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    182\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    183\u001B[0m             \u001B[0minstance\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__wrapped__\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"__self__\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\datascience-gpu\\lib\\site-packages\\nengo_dl\\simulator.py\u001B[0m in \u001B[0;36mrequire_open\u001B[1;34m(wrapped, instance, args, kwargs)\u001B[0m\n\u001B[0;32m     71\u001B[0m         )\n\u001B[0;32m     72\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 73\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mwrapped\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     74\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\datascience-gpu\\lib\\site-packages\\nengo_dl\\simulator.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, n_steps, stateful, **kwargs)\u001B[0m\n\u001B[0;32m    859\u001B[0m             \u001B[0mx_val\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    860\u001B[0m             \u001B[0mx_val\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_generate_inputs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_val\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_steps\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mn_steps\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 861\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_check_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_val\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_steps\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mn_steps\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    862\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    863\u001B[0m             \u001B[0my_val\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\datascience-gpu\\lib\\site-packages\\nengo_dl\\simulator.py\u001B[0m in \u001B[0;36m_check_data\u001B[1;34m(self, data, batch_size, n_steps, nodes)\u001B[0m\n\u001B[0;32m   1967\u001B[0m                     \u001B[1;34m\"should have rank 3 (batch_size, n_steps, dimensions), \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1968\u001B[0m                     \u001B[1;34m\"found rank %d\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1969\u001B[1;33m                     \u001B[1;34m\"%s data\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1970\u001B[0m                 )\n\u001B[0;32m   1971\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m<\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mminibatch_size\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValidationError\u001B[0m: input_4 data: should have rank 3 (batch_size, n_steps, dimensions), found rank 4"
     ]
    }
   ],
   "source": [
    "# Monte Carlo Cross Validation\n",
    "\n",
    "# split data into 3/4 as training and 1/4 as testing\n",
    "train_x, test_x, train_y, test_y = sklearn.model_selection.train_test_split(\n",
    "    features, labels, test_size=0.25, random_state=seed\n",
    ")\n",
    "\n",
    "shuffle_split = sklearn.model_selection.ShuffleSplit(\n",
    "    n_splits=30, test_size=0.25, random_state=seed\n",
    ")\n",
    "\n",
    "iter = 0\n",
    "validation_metrics, test_metrics, snn_metrics = [], [], []\n",
    "for training, validation in shuffle_split.split(train_x, train_y):\n",
    "    run_model(\n",
    "        validation_metrics=validation_metrics,\n",
    "        test_metrics=test_metrics,\n",
    "        snn_metrics=snn_metrics,\n",
    "        train_x = train_x[training],\n",
    "        train_y= train_y[training],\n",
    "        validation_x= train_x[validation],\n",
    "        validation_y= train_y[validation],\n",
    "        test_x=test_x,\n",
    "        test_y=test_y\n",
    "    )\n",
    "    iter += 1\n",
    "\n",
    "print(validation_metrics, test_metrics, snn_metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-9c9070f4",
   "language": "python",
   "display_name": "PyCharm (use-of-snn)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}