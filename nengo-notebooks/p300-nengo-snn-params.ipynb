{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import statistics\n",
    "import nengo\n",
    "import keras\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import nengo_dl\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from tensorflow.python.keras import Input, Model\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras.layers import Conv2D, BatchNormalization, Dropout, AveragePooling2D, Flatten, Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_path = os.path.join('..', 'datasets', 'VarekaGTNEpochs.mat') # path to dataset\n",
    "os.makedirs('nengo', exist_ok=True) # make folder for param files\n",
    "\n",
    "seed = 0 # set seed to produce same results\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataset(file = dataset_path):\n",
    "    \"\"\"\n",
    "    Helper function to get dataset from file.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    np_file = loadmat(file) # load dataset file with matrices\n",
    "    target_data, non_target_data = np_file['allTargetData'], np_file['allNonTargetData'] # get target and non-target data\n",
    "    features = np.concatenate((target_data, non_target_data)) # concatenate target and non-target into features\n",
    "\n",
    "    # target labels are represented as (1, 0) vector, non target labels are represented as (0, 1) vector\n",
    "    target_labels = np.tile(np.array([1, 0]), (target_data.shape[0], 1)) # set 'target' as (1, 0) vector\n",
    "    non_target_labels = np.tile(np.array([0, 1]), (non_target_data.shape[0], 1)) # set 'non target' as (0, 1) vector\n",
    "    labels = np.vstack((target_labels, non_target_labels)) # concatenate target and non target labels\n",
    "\n",
    "    # filter noise above 100 mV\n",
    "    threshold = 100.0\n",
    "    x_result, y_result = [], []\n",
    "    for i in range(features.shape[0]):\n",
    "        if not np.max(np.abs(features[i])) > threshold:\n",
    "            x_result.append(features[i])\n",
    "            y_result.append(labels[i])\n",
    "\n",
    "    features, labels = np.array(x_result), np.array(y_result)\n",
    "    features = features.reshape((features.shape[0], 1, -1))\n",
    "    labels = labels.reshape((labels.shape[0], 1, -1))\n",
    "\n",
    "    print('features:', features, features.shape)\n",
    "    print('labels:', labels, labels.shape)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"\n",
    "    Function to create tensorflow model\n",
    "    \"\"\"\n",
    "    inp = Input(shape=(3, 1200, 1), name='input_layer')\n",
    "    conv2d = Conv2D(filters=6, kernel_size=(3, 3), activation=tf.nn.relu)(inp)\n",
    "    dropout1 = Dropout(0.5, seed=seed)(conv2d)\n",
    "    avg_pooling = AveragePooling2D(pool_size=(1, 8), padding='same')(dropout1)\n",
    "    flatten = Flatten()(avg_pooling)\n",
    "    dense1 = Dense(100, activation=tf.nn.relu)(flatten)\n",
    "    batch_norm = BatchNormalization()(dense1)\n",
    "    dropout2 = Dropout(0.5, seed=seed)(batch_norm)\n",
    "    output = Dense(2, activation=tf.nn.softmax, name='output_layer')(dropout2)\n",
    "\n",
    "    return Model(inputs=inp, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_ann(model, train, valid, test, params_save_path, iteration, shuffle_training=True):\n",
    "    \"\"\"\n",
    "    Run ann via Nengo simulator. This fits given model with training data (train) and validates it using validation\n",
    "    data (valid). Then accuracy is calculated using test data (test) and weights are saved to params_save_path\n",
    "    :param shuffle_training: whether to shuffle data\n",
    "    :param model: tensorflow model created from create_model() function\n",
    "    :param train: pair of features and labels from training data\n",
    "    :param valid: pair of features and labels from validation data\n",
    "    :param test: pair of features and labels from test data\n",
    "    :param params_save_path: output path to save weights of the network for SNN testing\n",
    "    :return accuracy on test data\n",
    "    \"\"\"\n",
    "    x_train, y_train = train[0], train[1]\n",
    "    x_valid, y_valid = valid[0], valid[1]\n",
    "    x_test, y_test = test[0], test[1]\n",
    "\n",
    "    converter = nengo_dl.Converter(model)\n",
    "    with nengo_dl.Simulator(converter.net, minibatch_size=16) as simulator:\n",
    "        # some data will get truncated due to batch size\n",
    "        simulator.compile(\n",
    "            optimizer=keras.optimizers.Adam(),\n",
    "            loss=keras.losses.BinaryCrossentropy(),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        input_layer = converter.inputs[model.get_layer('input_layer')] # get nengo input\n",
    "        output_layer = converter.outputs[model.get_layer('output_layer')] # get nengo output\n",
    "\n",
    "        simulator.fit(\n",
    "            x={ input_layer: x_train }, y={ output_layer: y_train },\n",
    "            validation_data=({ input_layer: x_valid }, { output_layer: y_valid }),\n",
    "            epochs=30,\n",
    "            shuffle=shuffle_training,\n",
    "            callbacks=[EarlyStopping(patience=5, verbose=1, restore_best_weights=True)] # early stop to avoid overfitting\n",
    "        ) # train model\n",
    "\n",
    "        simulator.save_params(params_save_path) # save params for SNN\n",
    "        ann_eval = simulator.evaluate(x={ input_layer: x_test }, y={ output_layer: y_test }) # evaluate accuracy\n",
    "        print('{}. ann accuracy: {:5f}%'.format(iteration, ann_eval['probe_accuracy'] * 100)) # log accuracy\n",
    "        return ann_eval['probe_accuracy'] # return accuracy\n",
    "\n",
    "def run_snn(model, test, params_load_path, timesteps, scale_firing_rates, synapse, iteration):\n",
    "    \"\"\"\n",
    "    Runs SNN on test data. Loads pre-trained weights from params_load path and uses timesteps, scale_firing_rates and synapse\n",
    "    parameters for simulator.\n",
    "    :param model:\n",
    "    :param test:\n",
    "    :param params_load_path:\n",
    "    :param timesteps:\n",
    "    :param scale_firing_rates:\n",
    "    :param synapse:\n",
    "    :param iteration:\n",
    "    :return: accuracy calculated from predicted data\n",
    "    \"\"\"\n",
    "    converter = nengo_dl.Converter(\n",
    "        model=model,\n",
    "        swap_activations={ tf.nn.relu: nengo.SpikingRectifiedLinear() },\n",
    "        scale_firing_rates=scale_firing_rates,\n",
    "        synapse=synapse\n",
    "    )\n",
    "\n",
    "    x_test, y_test = test[0], test[1]\n",
    "\n",
    "    with converter.net:\n",
    "        nengo_dl.configure_settings(stateful=False)\n",
    "\n",
    "    input_layer = converter.inputs[model.get_layer('input_layer')] # input layer for simulator\n",
    "    output_layer = converter.outputs[model.get_layer('output_layer')] # output layer for simulator\n",
    "\n",
    "    x_test_time_tiled = np.tile(x_test, (1, timesteps, 1)) # tile x_test to match desired timesteps for simulator\n",
    "\n",
    "    with nengo_dl.Simulator(converter.net, minibatch_size=41, progress_bar=False) as simulator:\n",
    "        simulator.load_params(params_load_path)\n",
    "\n",
    "        predictions = simulator.predict({ input_layer: x_test_time_tiled })[output_layer] # get results from prediction\n",
    "        predictions = predictions[:,-1,:] # get last timestep\n",
    "\n",
    "        predictions = np.argmax(predictions, axis=-1) # get argmax\n",
    "        y_test = np.squeeze(y_test, axis=1) # remove time dimension from labels since its not relevant\n",
    "        y_test = np.argmax(y_test, axis=-1) # get argmax of y test as well for comparison\n",
    "\n",
    "        snn_avg = (predictions == y_test).mean()\n",
    "\n",
    "        if synapse is None:\n",
    "            print('{}. snn [timesteps={}, scale_firing_rates={}, synapse=None], accuracy: {:4f}%'\n",
    "                .format(iteration, timesteps, scale_firing_rates, snn_avg*100))\n",
    "        else:\n",
    "            print('{}. snn [timesteps={}, scale_firing_rates={}, synapse={:5f}], accuracy: {:4f}%'\n",
    "                .format(iteration, timesteps, scale_firing_rates, synapse, snn_avg*100))\n",
    "\n",
    "        return snn_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "features: [[[ -0.77055806  -0.76216829  -0.75329262 ...   0.9730792    1.04828787\n",
      "     1.00901747]]\n",
      "\n",
      " [[  4.72857332   4.79228735   4.86664867 ... -15.98517323 -16.30454826\n",
      "   -16.64167595]]\n",
      "\n",
      " [[ -2.2145133   -1.49968874  -0.77021754 ...  -6.05920124  -5.69483948\n",
      "    -5.42987347]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  9.08650398   9.06958485   9.0740099  ...  18.27712059  17.41079521\n",
      "    16.49032021]]\n",
      "\n",
      " [[  3.50287008   2.95584893   2.36093497 ...  20.93103218  21.30741882\n",
      "    21.62874603]]\n",
      "\n",
      " [[-14.8089571  -14.57761955 -14.33197689 ...  32.55890274  32.86030197\n",
      "    33.12610626]]] (8036, 1, 3600)\n",
      "labels: [[[1 0]]\n",
      "\n",
      " [[1 0]]\n",
      "\n",
      " [[1 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 1]]\n",
      "\n",
      " [[0 1]]\n",
      "\n",
      " [[0 1]]] (8036, 1, 2)\n",
      "train_x: [[[ -0.5420959   -1.21452522  -1.89456093 ...  -1.16598654  -1.73066759\n",
      "    -2.2462945 ]]\n",
      "\n",
      " [[ -9.35857487  -9.43084145  -9.40663052 ...  -1.80052102  -0.70815951\n",
      "     0.17630903]]\n",
      "\n",
      " [[  4.39046383   3.40499306   2.36262703 ...  38.03783417  38.5178566\n",
      "    38.89231491]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-19.15268135 -19.42535782 -19.74151993 ... -18.02782631 -18.95302963\n",
      "   -19.84547424]]\n",
      "\n",
      " [[ -6.18331957  -6.31638765  -6.51171541 ...  -2.18290114  -0.5134446\n",
      "     1.11941528]]\n",
      "\n",
      " [[ -1.88119197  -1.94168174  -2.00751877 ...  16.48749733  16.58769226\n",
      "    16.59143066]]], shape: (6027, 1, 3600), train_y: [[[0 1]]\n",
      "\n",
      " [[1 0]]\n",
      "\n",
      " [[0 1]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1 0]]\n",
      "\n",
      " [[1 0]]\n",
      "\n",
      " [[1 0]]], shape: (6027, 1, 2)\n",
      "test_x: [[[-10.23770618  -9.63037395  -8.99108791 ... -28.15560532 -28.65115166\n",
      "   -29.07019806]]\n",
      "\n",
      " [[ -3.7638278   -3.64355755  -3.53627396 ...  12.83851528  13.38534641\n",
      "    13.91609573]]\n",
      "\n",
      " [[-16.76546288 -17.07255745 -17.2746067  ... -41.82131195 -40.9500885\n",
      "   -40.11417389]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ -8.48158264  -9.23711395  -9.8549881  ... -54.10660172 -53.29751205\n",
      "   -52.48655701]]\n",
      "\n",
      " [[  2.34872699   2.34612942   2.36485052 ... -15.23301029 -15.09253597\n",
      "   -14.95751572]]\n",
      "\n",
      " [[ -8.25833607  -7.88723993  -7.51548815 ... -16.93505287 -16.60411263\n",
      "   -16.29413414]]], shape: (2009, 1, 3600), test_y: [[[0 1]]\n",
      "\n",
      " [[1 0]]\n",
      "\n",
      " [[0 1]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 1]]\n",
      "\n",
      " [[0 1]]\n",
      "\n",
      " [[0 1]]], shape: (2009, 1, 2)\n",
      "Iteration: 1\n",
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Construction finished in 0:00:00                                               \n",
      "Epoch 1/30\n",
      "282/282 [==============================] - 4s 13ms/step - loss: 0.9235 - probe_loss: 0.9235 - probe_accuracy: 0.5525 - val_loss: 0.7066 - val_probe_loss: 0.7066 - val_probe_accuracy: 0.6097\n",
      "Epoch 2/30\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.7194 - probe_loss: 0.7194 - probe_accuracy: 0.5960 - val_loss: 0.6665 - val_probe_loss: 0.6665 - val_probe_accuracy: 0.6217\n",
      "Epoch 3/30\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 0.6730 - probe_loss: 0.6730 - probe_accuracy: 0.6133 - val_loss: 0.6629 - val_probe_loss: 0.6629 - val_probe_accuracy: 0.6144\n",
      "Epoch 4/30\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 0.6594 - probe_loss: 0.6594 - probe_accuracy: 0.6106 - val_loss: 0.6579 - val_probe_loss: 0.6579 - val_probe_accuracy: 0.6356\n",
      "Epoch 5/30\n",
      "282/282 [==============================] - 3s 11ms/step - loss: 0.6534 - probe_loss: 0.6534 - probe_accuracy: 0.6350 - val_loss: 0.6593 - val_probe_loss: 0.6593 - val_probe_accuracy: 0.6283\n",
      "Epoch 6/30\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 0.6430 - probe_loss: 0.6430 - probe_accuracy: 0.6394 - val_loss: 0.6567 - val_probe_loss: 0.6567 - val_probe_accuracy: 0.6416\n",
      "Epoch 7/30\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 0.6383 - probe_loss: 0.6383 - probe_accuracy: 0.6416 - val_loss: 0.6659 - val_probe_loss: 0.6659 - val_probe_accuracy: 0.6124\n",
      "Epoch 8/30\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 0.6394 - probe_loss: 0.6394 - probe_accuracy: 0.6363 - val_loss: 0.6538 - val_probe_loss: 0.6538 - val_probe_accuracy: 0.6277\n",
      "Epoch 9/30\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 0.6422 - probe_loss: 0.6422 - probe_accuracy: 0.6325 - val_loss: 0.6542 - val_probe_loss: 0.6542 - val_probe_accuracy: 0.6263\n",
      "Epoch 10/30\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 0.6384 - probe_loss: 0.6384 - probe_accuracy: 0.6370 - val_loss: 0.6619 - val_probe_loss: 0.6619 - val_probe_accuracy: 0.6197\n",
      "Epoch 11/30\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 0.6364 - probe_loss: 0.6364 - probe_accuracy: 0.6385 - val_loss: 0.6552 - val_probe_loss: 0.6552 - val_probe_accuracy: 0.6197\n",
      "Epoch 12/30\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 0.6290 - probe_loss: 0.6290 - probe_accuracy: 0.6445 - val_loss: 0.6728 - val_probe_loss: 0.6728 - val_probe_accuracy: 0.6250\n",
      "Epoch 13/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.6329 - probe_loss: 0.6329 - probe_accuracy: 0.6407Restoring model weights from the end of the best epoch.\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.6329 - probe_loss: 0.6329 - probe_accuracy: 0.6407 - val_loss: 0.6615 - val_probe_loss: 0.6615 - val_probe_accuracy: 0.6124\n",
      "Epoch 00013: early stopping\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.6444 - probe_loss: 0.6444 - probe_accuracy: 0.6345\n",
      "1. ann accuracy: 63.450003%\n",
      "1. snn [timesteps=50, scale_firing_rates=1000, synapse=0.010000], accuracy: 63.464410%\n",
      "1. snn [timesteps=50, scale_firing_rates=1, synapse=0.010000], accuracy: 53.459433%\n",
      "1. snn [timesteps=50, scale_firing_rates=1000, synapse=None], accuracy: 63.315082%\n",
      "1. snn [timesteps=50, scale_firing_rates=1, synapse=None], accuracy: 52.314584%\n",
      "Iteration: 2\n",
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Construction finished in 0:00:01                                               \n",
      "Epoch 1/30\n",
      "282/282 [==============================] - 4s 12ms/step - loss: 0.9596 - probe_loss: 0.9596 - probe_accuracy: 0.5536 - val_loss: 0.6919 - val_probe_loss: 0.6919 - val_probe_accuracy: 0.6137\n",
      "Epoch 2/30\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 0.7122 - probe_loss: 0.7122 - probe_accuracy: 0.5953 - val_loss: 0.6641 - val_probe_loss: 0.6641 - val_probe_accuracy: 0.6230\n",
      "Epoch 3/30\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 0.6771 - probe_loss: 0.6771 - probe_accuracy: 0.6062 - val_loss: 0.6484 - val_probe_loss: 0.6484 - val_probe_accuracy: 0.6323\n",
      "Epoch 4/30\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 0.6540 - probe_loss: 0.6540 - probe_accuracy: 0.6210 - val_loss: 0.6477 - val_probe_loss: 0.6477 - val_probe_accuracy: 0.6356\n",
      "Epoch 5/30\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.6520 - probe_loss: 0.6520 - probe_accuracy: 0.6195 - val_loss: 0.6540 - val_probe_loss: 0.6540 - val_probe_accuracy: 0.6343\n",
      "Epoch 6/30\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.6492 - probe_loss: 0.6492 - probe_accuracy: 0.6308 - val_loss: 0.6483 - val_probe_loss: 0.6483 - val_probe_accuracy: 0.6403\n",
      "Epoch 7/30\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.6447 - probe_loss: 0.6447 - probe_accuracy: 0.6305 - val_loss: 0.6497 - val_probe_loss: 0.6497 - val_probe_accuracy: 0.6283\n",
      "Epoch 8/30\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 0.6399 - probe_loss: 0.6399 - probe_accuracy: 0.6328 - val_loss: 0.6533 - val_probe_loss: 0.6533 - val_probe_accuracy: 0.6370\n",
      "Epoch 9/30\n",
      " 44/282 [===>..........................] - ETA: 2s - loss: 0.6138 - probe_loss: 0.6138 - probe_accuracy: 0.6406"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-073bb1df7453>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# run ann\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     ann_result = run_ann(model=model,\n\u001b[0m\u001b[0;32m     32\u001b[0m                          \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_current\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_current\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                          \u001b[0mvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid_current\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid_current\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-d1324de2f3dc>\u001b[0m in \u001b[0;36mrun_ann\u001b[1;34m(model, train, valid, test, params_save_path, iteration, shuffle_training)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0moutput_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'output_layer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# get nengo output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         simulator.fit(\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m \u001b[0minput_layer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_train\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m \u001b[0minput_layer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_valid\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_valid\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data-science\\lib\\site-packages\\nengo\\utils\\magic.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0minstance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__self__\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data-science\\lib\\site-packages\\nengo_dl\\simulator.py\u001b[0m in \u001b[0;36mrequire_open\u001b[1;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m         )\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data-science\\lib\\site-packages\\nengo_dl\\simulator.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, n_steps, stateful, **kwargs)\u001b[0m\n\u001b[0;32m    872\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"validation_data\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 874\u001b[1;33m         return self._call_keras(\n\u001b[0m\u001b[0;32m    875\u001b[0m             \u001b[1;34m\"fit\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstateful\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data-science\\lib\\site-packages\\nengo\\utils\\magic.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0minstance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__self__\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data-science\\lib\\site-packages\\nengo_dl\\simulator.py\u001b[0m in \u001b[0;36mwith_self\u001b[1;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_floatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data-science\\lib\\site-packages\\nengo_dl\\simulator.py\u001b[0m in \u001b[0;36m_call_keras\u001b[1;34m(self, func_type, x, y, n_steps, stateful, **kwargs)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             \u001b[0mfunc_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# update n_steps/time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data-science\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data-science\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data-science\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data-science\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data-science\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data-science\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data-science\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data-science\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data-science\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features, labels = get_dataset()\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=.25, random_state=seed, shuffle=True)\n",
    "\n",
    "print('train_x: {}, shape: {}, train_y: {}, shape: {}'.format(x_train, x_train.shape, y_train, y_train.shape))\n",
    "print('test_x: {}, shape: {}, test_y: {}, shape: {}'.format(x_test, x_test.shape, y_test, y_test.shape))\n",
    "\n",
    "ann, snn = [], []\n",
    "\n",
    "# 'hyper-parameters' with format: timesteps, scale_firing_rates, synapse\n",
    "snn_config = [\n",
    "    [50, 1000, 0.01], # best performing parameters for simulator\n",
    "    [50, 1000, None], # synaptic smoothing turned off\n",
    "    [50, 1, 0.01], # spike scaling turned off\n",
    "    [50, 1, None] # everything turned off, only RELU is swapped for spiking RELU\n",
    "]\n",
    "\n",
    "n_iterations = 30 # iterations of cross-valiation\n",
    "iteration = 1 # number of current iteration\n",
    "monte_carlo = ShuffleSplit(n_splits=n_iterations, test_size=.25, random_state=seed)\n",
    "for train, valid in monte_carlo.split(x_train):\n",
    "    print('Iteration: {}'.format(iteration)) # Print number of iteration\n",
    "\n",
    "    x_train_current, y_train_current = x_train[train], y_train[train] # get training data for current iteration\n",
    "    x_valid_current, y_valid_current = x_train[valid], y_train[valid] # get validation data for current iteration\n",
    "\n",
    "    params_path = os.path.join('nengo', 'params_iter_{}'.format(iteration)) # path to weights for current iteration\n",
    "\n",
    "    model = create_model() # create model\n",
    "\n",
    "    # run ann\n",
    "    ann_result = run_ann(model=model,\n",
    "                         train=(x_train_current, y_train_current),\n",
    "                         valid=(x_valid_current, y_valid_current),\n",
    "                         test=(x_test, y_test),\n",
    "                         params_save_path=params_path,\n",
    "                         iteration=iteration\n",
    "                         )\n",
    "    K.clear_session() # clear session\n",
    "    ann.append(ann_result)\n",
    "\n",
    "    # run spiking network for each combination of timesteps, spike scaling and synapse and append it to the snn_results\n",
    "    snn_results = []\n",
    "    for variant in snn_config:\n",
    "        snn_acc = run_snn(model=model,\n",
    "                          test=(x_test, y_test),\n",
    "                          params_load_path=params_path,\n",
    "                          timesteps=variant[0],\n",
    "                          scale_firing_rates=variant[1],\n",
    "                          synapse=variant[2],\n",
    "                          iteration=iteration\n",
    "                          )\n",
    "        K.clear_session() # clear session not to cause a memory leak\n",
    "        snn_results.append(snn_acc)\n",
    "\n",
    "    del model # delete model to avoid potential memory leak (this might be unnecessary)\n",
    "    iteration += 1\n",
    "    # append list of accuracies for each parameter variant to the snn list\n",
    "    snn.append(snn_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_stats(ann, snn, snn_config, snn_config_output, xlsx_output, average_accs_output):\n",
    "    \"\"\"\n",
    "    Save statistics to excel file. These were further used in p300-nengo-visualization notebook\n",
    "    :param ann: accuracies of ann network\n",
    "    :param snn: accuracies of snn network\n",
    "    :param snn_config: list of configurations for snn\n",
    "    :param snn_config_output: name of json file where configs for snn will be saved\n",
    "    :param xlsx_output: name of output file\n",
    "    :param average_accs_output: name of file containing average accuracy and std\n",
    "    \"\"\"\n",
    "\n",
    "    snn_config_array = []\n",
    "    for variant in snn_config:\n",
    "        snn_config_array.append({\n",
    "            'timesteps': variant[0],\n",
    "            'scale_firing_rates': variant[1],\n",
    "            'synapse': variant[2] if variant[2] is not None else 'None'\n",
    "        })\n",
    "\n",
    "    with open(snn_config_output, 'w') as file:\n",
    "        json.dump(snn_config_array, file)\n",
    "\n",
    "    data = {\n",
    "        'iterations': [x for x in range(1, len(ann) + 1)],\n",
    "        'ann_accuracy': ann,\n",
    "    } # data dictionary for pandas dataframe\n",
    "\n",
    "    variants = [] # create key for data dictionary for each configuration of snn\n",
    "    for variant in snn_config:\n",
    "        # synapse can be None which is cannot be passed as format parameter for some reason\n",
    "        if variant[2] is None:\n",
    "            variants.append('snn [timesteps={}, scaling={}, synapse=None]'\n",
    "                            .format(variant[0], int(variant[1])))\n",
    "        else:\n",
    "            variants.append('snn [timesteps={}, scaling={}, synapse={:3f}]'\n",
    "                        .format(variant[0], int(variant[1]), variant[2]))\n",
    "\n",
    "    # split accuracies for each configuration to specific list\n",
    "    # meaning each accuracy with configuration \"A\" will be in list on index a ...\n",
    "    snn_accs_by_variant = [[] for _ in range(len(variants))]\n",
    "    for snn_acc_list in snn:\n",
    "        for i in range(len(snn_acc_list)):\n",
    "            snn_accs_by_variant[i].append(snn_acc_list[i])\n",
    "\n",
    "    # add accuracies for each snn configuration to the dataset\n",
    "    for i in range(len(variants)):\n",
    "        data[variants[i]] = snn_accs_by_variant[i]\n",
    "\n",
    "    # create dataframe, print it and save as excel spreadsheet\n",
    "    df = pd.DataFrame(data=data, index=list(range(1, len(ann) + 1)))\n",
    "    print(df)\n",
    "    df.to_excel(xlsx_output)\n",
    "\n",
    "    # create dataframe for average accuracies and their sample standard deviations\n",
    "\n",
    "    data_stats = {\n",
    "        'model': ['ANN'] + variants,\n",
    "        'average_accuracy': [],\n",
    "        'sample_standard_deviation': []\n",
    "    }\n",
    "\n",
    "    data_stats['average_accuracy'].append(statistics.mean(ann))\n",
    "    data_stats['sample_standard_deviation'].append(statistics.stdev(ann))\n",
    "\n",
    "    for snn_acc in snn_accs_by_variant:\n",
    "        data_stats['average_accuracy'].append(statistics.mean(snn_acc))\n",
    "        data_stats['sample_standard_deviation'].append(statistics.stdev(snn_acc))\n",
    "    \n",
    "    df_stats = pd.DataFrame(data=data_stats) # create dataframe for stats\n",
    "    df_stats.to_excel(average_accs_output, index=False) # save to excel\n",
    "\n",
    "    #\n",
    "    # # create graph. Graph will be 130% of default size to ensure readability since it contains a lot of data\n",
    "    # df.plot(x='iterations', y=['ann_accuracy'] + variants, kind='bar', title='Accuracy of ANN and respective variant of SNN per iteration',\n",
    "    #         figsize=[6.4 * 3, 4.8 * 3], width=0.9)\n",
    "    # plt.yticks(np.arange(0, 1.0, 0.05))\n",
    "    # plt.xticks(rotation=0)\n",
    "    # plt.ylabel('Accuracy')\n",
    "    # plt.xlabel('Iterations')\n",
    "    # # plt.legend(loc='upper left', bbox_to_anchor=(1.01, 1), borderaxespad=0.)\n",
    "    # plt.legend(loc='lower left', bbox_to_anchor= (0.0, 1.05), ncol=3,\n",
    "    #         borderaxespad=0, frameon=False)\n",
    "    # plt.savefig(graph_output, format=graph_format, bbox_inches='tight')\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save_stats(ann=ann,\n",
    "          snn=snn,\n",
    "          snn_config=snn_config,\n",
    "          snn_config_output=os.path.join('output', 'snn_config.json'),\n",
    "          xlsx_output=os.path.join('output', 'values.xlsx'),\n",
    "          average_accs_output=os.path.join('output','accs.xlsx')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (use-of-snn)",
   "language": "python",
   "name": "pycharm-9c9070f4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}