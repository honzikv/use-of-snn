{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This notebook uses data from each participant individually. A spiking neural network is created for every participant\n",
    "and then tested on 25% of the participant's data which were previously not used for training."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import nengo_dl\n",
    "import nengo\n",
    "from tensorflow.python.keras import Input, Model\n",
    "from tensorflow.python.keras.layers import Conv2D, Dropout, AveragePooling2D, Flatten, Dense, BatchNormalization, Conv3D\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dataset_path = os.path.join('dataset_result')\n",
    "files = [os.path.join(dataset_path, 'P{:02d}.npz'.format(i+1))\n",
    "         for i in range(18)] # P01 - P18 files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we check data for the first file,\n",
    "these operations are later applied for every file of the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 14, 36, 10)\n",
      "(120,)\n"
     ]
    }
   ],
   "source": [
    "# Check data in the first file then apply it for every file\n",
    "dataset = np.load(files[0])\n",
    "features, labels = dataset['features'], dataset['labels']\n",
    "\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no' 'yes' 'no']\n"
     ]
    }
   ],
   "source": [
    "print(labels[50:53]) # no, yes, no"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [1.]\n",
      " [1.]]\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[[[1. 0.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "cat = OneHotEncoder()\n",
    "labels = labels.reshape(-1, 1)\n",
    "print(labels[50:53])\n",
    "labels = cat.fit_transform(labels).toarray()\n",
    "print(labels[50:53])\n",
    "labels = labels.reshape((labels.shape[0], 1, -1)) # add time dimension for nengo\n",
    "print(labels[50:53])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now define tensorflow models which will be tested\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def cnn_model_1():\n",
    "    \"\"\"\n",
    "    Creates a CNN neural network\n",
    "    :return: tensorflow model of the ANN\n",
    "    \"\"\"\n",
    "\n",
    "    inp = Input(shape=(14, 360, 1), name='input_layer')\n",
    "    conv2d = Conv2D(filters=9, kernel_size=(3, 3), activation='relu')(inp)\n",
    "    dropout1 = Dropout(0.5, seed=seed)(conv2d)\n",
    "    avg_pooling = AveragePooling2D(pool_size=(2, 2))(dropout1)\n",
    "    flatten = Flatten()(avg_pooling)\n",
    "    dense1 = Dense(1000, activation='relu')(flatten)\n",
    "    batch_norm = BatchNormalization()(dense1)\n",
    "    dense2 = Dense(500, activation='relu')(batch_norm)\n",
    "    dropout2 = Dropout(0.5, seed=seed)(dense2)\n",
    "    output = Dense(2, activation='softmax', name='output_layer')(dropout2)\n",
    "\n",
    "    return Model(inputs=inp, outputs=output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "def train_model(model, x_train, y_train, params_output_path, num_epochs=10):\n",
    "    converter = nengo_dl.Converter(model)\n",
    "\n",
    "    with nengo_dl.Simulator(converter.net, minibatch_size=4) as simulator:\n",
    "        simulator.compile(\n",
    "            optimizer=keras.optimizers.Adam(),\n",
    "            loss=keras.losses.BinaryCrossentropy(),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        input_layer = converter.inputs[model.get_layer('input_layer')]\n",
    "        output_layer = converter.outputs[model.get_layer('output_layer')]\n",
    "\n",
    "        simulator.fit(\n",
    "            x={ input_layer: x_train },\n",
    "            y={ output_layer: y_train },\n",
    "            epochs=num_epochs,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        simulator.save_params(params_output_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_model(model, params_path, x_test, y_test, scale_firing_rates=1000, synapse=0.01, timesteps=30):\n",
    "\n",
    "    converter = nengo_dl.Converter(model)\n",
    "    with nengo_dl.Simulator(converter.net, minibatch_size=4) as simulator:\n",
    "        simulator.load_params(params_path)\n",
    "\n",
    "        input_layer = converter.inputs[model.get_layer('input_layer')]\n",
    "        output_layer = converter.outputs[model.get_layer('output_layer')]\n",
    "\n",
    "        ann_eval = simulator.evaluate(\n",
    "            x={ input_layer: x_test },\n",
    "            y={ output_layer: y_test }\n",
    "        ) # results from ann\n",
    "\n",
    "    # Converter for nengo spiking network\n",
    "    converter = nengo_dl.Converter(\n",
    "        model,\n",
    "        swap_activations={ tf.nn.relu: nengo.SpikingRectifiedLinear() },\n",
    "        scale_firing_rates=scale_firing_rates,\n",
    "        synapse=synapse\n",
    "    )\n",
    "\n",
    "    with converter.net:\n",
    "        nengo_dl.configure_settings(stateful=False)\n",
    "\n",
    "    input_layer = converter.inputs[model.get_layer('input_layer')] # input layer for simulator\n",
    "    output_layer = converter.outputs[model.get_layer('output_layer')] # output layer for simulator\n",
    "\n",
    "    x_test_tiled = np.tile(x_test, (1, timesteps, 1))\n",
    "\n",
    "    with nengo_dl.Simulator(converter.net, minibatch_size=4) as simulator:\n",
    "        simulator.load_params(params_path)\n",
    "\n",
    "        predictions = simulator.predict({ input_layer: x_test_tiled })[output_layer]\n",
    "        predictions = predictions[:, -1, :] # get last timestep from prediction\n",
    "        y_test = np.squeeze(y_test, axis=1)\n",
    "        y_test = np.argmax(y_test, axis=-1)\n",
    "\n",
    "        snn_acc = (predictions == y_test).mean()\n",
    "\n",
    "    return ann_eval, snn_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}