{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "seed = 0\n",
    "torch.manual_seed(seed) # seed for consistency\n",
    "np.random.seed(seed)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set data type for computations in the neural network\n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_firing_time(x, tau=20, thr=0.2, tmax=1.0, epsilon=1e-7):\n",
    "    idx = x < thr\n",
    "    x = np.clip(x, thr + epsilon, 1e9)\n",
    "    T = tau * np.log(x / (x - thr))\n",
    "    T[idx] = tmax\n",
    "    return T\n",
    "\n",
    "def sparse_data_generator(x, y, batch_size, num_steps, num_units, time_step=1e-3, shuffle=True):\n",
    "    labels_ = np.array(y, dtype=np.int)\n",
    "    number_of_batches = len(x) // batch_size\n",
    "    sample_index = np.arange(len(x))\n",
    "\n",
    "    # compute discrete firing times\n",
    "    tau_eff = 20e-3 / time_step\n",
    "    firing_times = np.array(convert_to_firing_time(x, tau=tau_eff, tmax=num_steps), dtype=np.int)\n",
    "    unit_numbers = np.arange(num_units)\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "\n",
    "    counter = 0\n",
    "    while counter < number_of_batches:\n",
    "        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n",
    "\n",
    "        coo = [[] for _ in range(3)]\n",
    "        for bc, idx in enumerate(batch_index):\n",
    "            c = firing_times[idx] < num_steps\n",
    "            times, units = firing_times[idx][c], unit_numbers[c]\n",
    "\n",
    "            batch = [bc for _ in range(len(times))]\n",
    "            coo[0].extend(batch)\n",
    "            coo[1].extend(times)\n",
    "            coo[2].extend(units)\n",
    "\n",
    "        i = torch.LongTensor(coo).to(device)\n",
    "        v = torch.FloatTensor(np.ones(len(coo[0]))).to(device)\n",
    "\n",
    "        X_batch = torch.sparse.FloatTensor(i, v, torch.Size([batch_size, num_steps, num_units])).to(device)\n",
    "        y_batch = torch.tensor(labels_[batch_index], device=device, dtype=torch.long)\n",
    "\n",
    "        yield X_batch.to(device=device), y_batch.to(device=device)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "class SurrGradSpike(torch.autograd.Function):\n",
    "    scale = 100.0  # controls steepness of surrogate gradient\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        out = torch.zeros_like(input)\n",
    "        out[input > 0] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad = grad_input / (SurrGradSpike.scale * torch.abs(input) + 1.0) ** 2\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class DeepSNNModel:\n",
    "    \"\"\"\n",
    "    This class implements a simple deep snn model that comprises a set of fully connected layers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, units: List[int], weight_scale: Tuple = (7.0, 1.0), recurrent=False, time_step=1e-3,\n",
    "                 tau_mem=10e-3,\n",
    "                 tau_syn=5e-3):\n",
    "        \"\"\"\n",
    "        :param units: list of units in each layer\n",
    "        :param weight_scale: tuple of one or two values, controls the scaling of the weights\n",
    "        :param recurrent: whether the network is recurrent one - additional recurrent weights are used\n",
    "        :param time_step: how long does one time step take (seconds)\n",
    "        :param tau_mem: membrane tau parameter\n",
    "        :param tau_syn: synapse tau parameter\n",
    "        \"\"\"\n",
    "        self.units = units\n",
    "        self.tau_mem = tau_mem\n",
    "        self.tau_syn = tau_syn\n",
    "        self.alpha = float(np.exp(-time_step / tau_syn))\n",
    "        self.beta = float(np.exp(-time_step / tau_mem))\n",
    "        self.is_recurrent = recurrent\n",
    "\n",
    "        if len(weight_scale) == 2:\n",
    "            self.weight_scale = weight_scale[0] * (weight_scale[1] - self.beta)\n",
    "        else:\n",
    "            self.weight_scale = weight_scale[0]\n",
    "        self.weights = self._init_weights()\n",
    "        self.recurrent_weights = None if not recurrent else self._init_recurrent_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"\n",
    "        Initializes weights between layers\n",
    "        :return: list of torch tensors representing weights\n",
    "        \"\"\"\n",
    "        weights = []\n",
    "        for i in range(len(self.units) - 1):\n",
    "            wi = torch.empty((self.units[i], self.units[i + 1]), device=device, dtype=dtype, requires_grad=True)\n",
    "            torch.nn.init.normal_(wi, mean=0.0, std=self.weight_scale / np.sqrt(self.units[i]))\n",
    "            weights.append(wi)\n",
    "        return weights\n",
    "\n",
    "    def _init_recurrent_weights(self):\n",
    "        \"\"\"\n",
    "        Initializes recurrent weights for recurrent network for every hidden layer\n",
    "        :return: list of torch tensors representing recurrent weights\n",
    "        \"\"\"\n",
    "        recurrent_weights = []\n",
    "        for i in range(1, len(self.units) - 1):\n",
    "            vi = torch.empty((self.units[i], self.units[i]), device=device, dtype=dtype, requires_grad=True)\n",
    "            torch.nn.init.normal_(vi, mean=0.0, std=self.weight_scale / np.sqrt(self.units[i]))\n",
    "            recurrent_weights.append(vi)\n",
    "        return recurrent_weights\n",
    "\n",
    "    def run_recurrent(self, inputs, batch_size, steps, spike_fn=SurrGradSpike.apply):\n",
    "        \"\"\"\n",
    "        Runs recurrent network\n",
    "        :param inputs: input data\n",
    "        :param batch_size: batch size\n",
    "        :param steps: number of timesteps\n",
    "        :param spike_fn: surrogate gradient function\n",
    "        :return: output layer results and\n",
    "        \"\"\"\n",
    "        layer_outputs = [inputs]\n",
    "        mem_recs = []\n",
    "        spike_recs = []\n",
    "\n",
    "        # compute activity in each hidden layer\n",
    "        for i in range(1, len(self.units) - 1):  # the current hidden layer index\n",
    "            hidden_units = self.units[i]  # neurons in the current hidden layer\n",
    "            syn_hidden_i = torch.zeros((batch_size, hidden_units), device=device, dtype=dtype)\n",
    "            mem_hidden_i = torch.zeros((batch_size, hidden_units), device=device, dtype=dtype)\n",
    "\n",
    "            mem_rec_hidden_i = [mem_hidden_i]\n",
    "            spike_rec_hidden_i = [mem_hidden_i]\n",
    "\n",
    "            hi = torch.zeros((batch_size, hidden_units), device=device, dtype=dtype)\n",
    "            hi_from_prev_layer = torch.einsum('abc, cd -> abd', (layer_outputs[i - 1], self.weights[i - 1]))\n",
    "\n",
    "            for dt in range(steps):\n",
    "                mem_threshold = mem_hidden_i - 1.0\n",
    "                spike_out = spike_fn(mem_threshold)\n",
    "                rst = torch.zeros_like(mem_hidden_i)\n",
    "                c = (mem_threshold > 0)\n",
    "                rst[c] = torch.ones_like(mem_hidden_i)[c]\n",
    "\n",
    "                hi = hi_from_prev_layer[:, dt] + torch.einsum('ab, bc -> ac', (hi, self.recurrent_weights[i - 1]))\n",
    "                new_syn = self.alpha * syn_hidden_i + hi\n",
    "                new_mem = self.beta * mem_hidden_i + syn_hidden_i - rst\n",
    "\n",
    "                mem_hidden_i = new_mem\n",
    "                syn_hidden_i = new_syn\n",
    "\n",
    "                mem_rec_hidden_i.append(mem_hidden_i)\n",
    "                spike_rec_hidden_i.append(spike_out)\n",
    "\n",
    "            spike_rec_hidden_i = torch.stack(spike_rec_hidden_i, dim=1)\n",
    "            mem_rec_hidden_i = torch.stack(mem_rec_hidden_i, dim=1)\n",
    "\n",
    "            layer_outputs.append(spike_rec_hidden_i)  # append output so it can be fed to the next hidden layer\n",
    "            mem_recs.append(mem_rec_hidden_i)\n",
    "            spike_recs.append(spike_rec_hidden_i)\n",
    "\n",
    "        # output layer\n",
    "        hn = torch.einsum('abc, cd -> abd', (layer_outputs[-1], self.weights[-1]))\n",
    "        flt = torch.zeros((batch_size, self.units[-1]), device=device, dtype=dtype)\n",
    "        spike_out = torch.zeros((batch_size, self.units[-1]), device=device, dtype=dtype)\n",
    "\n",
    "        out_rec = [spike_out]\n",
    "        for dt in range(steps):\n",
    "            new_flt = self.alpha * flt + hn[:, dt]\n",
    "            new_out = self.beta * spike_out + flt\n",
    "\n",
    "            flt = new_flt\n",
    "            spike_out = new_out\n",
    "\n",
    "            out_rec.append(spike_out)\n",
    "\n",
    "        out_rec = torch.stack(out_rec, dim=1)\n",
    "        return out_rec, spike_recs, layer_outputs, mem_recs\n",
    "\n",
    "    def run_feed_forward(self, inputs, batch_size, steps, spike_fn=SurrGradSpike.apply):\n",
    "        layer_outputs = [inputs]\n",
    "        mem_recs = []\n",
    "        spike_recs = []\n",
    "\n",
    "        # compute activity of every hidden layer\n",
    "        # hidden layers are stored from index 1 to index len(self.units) - 2\n",
    "        for i in range(1, len(self.units) - 1):\n",
    "            hidden_units = self.units[i]  # units in next layer\n",
    "\n",
    "            # sum of output from previous layer and weights of current hidden layer\n",
    "            hi = torch.einsum('abc,cd->abd', (layer_outputs[i - 1], self.weights[i - 1]))\n",
    "            syn_hidden_i = torch.zeros((batch_size, hidden_units), device=device, dtype=dtype)  # synapses\n",
    "            mem_hidden_i = torch.zeros((batch_size, hidden_units), device=device, dtype=dtype)  # membranes\n",
    "\n",
    "            mem_rec_hidden_i = [mem_hidden_i]\n",
    "            spike_rec_hidden_i = [mem_hidden_i]\n",
    "\n",
    "            for dt in range(steps):\n",
    "                mem_threshold = mem_hidden_i - 1.0\n",
    "                spike_out = spike_fn(mem_threshold)\n",
    "                rst = torch.zeros_like(mem_hidden_i)\n",
    "                c = (mem_threshold > 0)\n",
    "                rst[c] = torch.ones_like(mem_hidden_i)[c]\n",
    "\n",
    "                new_syn = self.alpha * syn_hidden_i + hi[:, dt]\n",
    "                new_mem = self.beta * mem_hidden_i + syn_hidden_i - rst\n",
    "                mem_hidden_i = new_mem\n",
    "                syn_hidden_i = new_syn\n",
    "\n",
    "                mem_rec_hidden_i.append(mem_hidden_i)\n",
    "                spike_rec_hidden_i.append(spike_out)\n",
    "\n",
    "            spike_rec_hidden_i = torch.stack(spike_rec_hidden_i, dim=1)\n",
    "            mem_rec_hidden_i = torch.stack(mem_rec_hidden_i, dim=1)\n",
    "\n",
    "            layer_outputs.append(spike_rec_hidden_i)  # append output so it can be fed to the next hidden layer\n",
    "            mem_recs.append(mem_rec_hidden_i)\n",
    "            spike_recs.append(spike_rec_hidden_i)\n",
    "\n",
    "        # readout layer\n",
    "        hn = torch.einsum('abc,cd->abd', (layer_outputs[-1], self.weights[-1]))\n",
    "        flt = torch.zeros((batch_size, self.units[-1]), device=device, dtype=dtype)\n",
    "        spike_out = torch.zeros((batch_size, self.units[-1]), device=device, dtype=dtype)\n",
    "\n",
    "        out_rec = [spike_out]\n",
    "        for dt in range(steps):\n",
    "            new_flt = self.alpha * flt + hn[:, dt]\n",
    "            new_out = self.beta * spike_out + flt\n",
    "            flt = new_flt\n",
    "            spike_out = new_out\n",
    "            out_rec.append(spike_out)\n",
    "\n",
    "        out_rec = torch.stack(out_rec, dim=1)\n",
    "        return out_rec, spike_recs, layer_outputs, mem_recs\n",
    "\n",
    "    def train(self, x_data, y_data, batch_size, num_steps=100, time_step=1e-3, lr=1e-3, num_epochs=10,\n",
    "              use_regularizer=False):\n",
    "\n",
    "        if not use_regularizer:\n",
    "            optimizer = torch.optim.Adam(self.weights, lr=lr, betas=(0.9, 0.999))\n",
    "        else:\n",
    "            optimizer = torch.optim.Adamax(self.weights, lr=lr, betas=(0.9, 0.999))\n",
    "        log_softmax_fn = nn.LogSoftmax(dim=1)\n",
    "        loss_fn = nn.NLLLoss()\n",
    "\n",
    "        loss_hist = []\n",
    "        for epoch in range(num_epochs):\n",
    "            local_loss = []\n",
    "            for x_local, y_local in sparse_data_generator(x_data, y_data, batch_size, num_steps, self.units[0],\n",
    "                                                          time_step):\n",
    "                # todo simplify\n",
    "                if not self.is_recurrent:  # if the network does not contain recurrent weights run it as feedforward\n",
    "                    output, spike_recs, layer_outputs, mem_recs = self.run_feed_forward(x_local.to_dense(), batch_size,\n",
    "                                                                                        num_steps)\n",
    "                else:\n",
    "                    output, spike_recs, layer_outputs, mem_recs = self.run_recurrent(x_local.to_dense(), batch_size,\n",
    "                                                                                     num_steps)\n",
    "\n",
    "                output_max, _ = torch.max(output, 1)\n",
    "                log_p_y = log_softmax_fn(output_max)\n",
    "\n",
    "                loss_val = loss_fn(log_p_y, y_local)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss_val.backward()\n",
    "                optimizer.step()\n",
    "                local_loss.append(loss_val.item())\n",
    "\n",
    "            mean_loss = np.mean(local_loss)\n",
    "            print('Epoch {}: loss={.5f}'.format(epoch + 1, mean_loss))\n",
    "            loss_hist.append(mean_loss)\n",
    "\n",
    "        return loss_hist\n",
    "\n",
    "\n",
    "def get_metrics(x_test, y_test, batch_size, snn_model, time_step=1e-3, num_steps=100):\n",
    "    predictions = []\n",
    "    for x_local, y_local in sparse_data_generator(x_test, y_test, batch_size, num_steps, snn_model.units[0], time_step,\n",
    "                                                  False):\n",
    "\n",
    "        # Run feedforward/recurrent network and get the output\n",
    "        output, spike_recs, layer_outputs, mem_recs = snn_model.run_recurrent(x_local.to_dense(), batch_size, num_steps) \\\n",
    "            if snn_model.recurrent_weights else snn_model.run_feed_forward(x_local.to_dense(), batch_size, num_steps)\n",
    "\n",
    "        output_max, _ = torch.max(output, 1)\n",
    "        _, output_argmax = torch.max(output_max, 1)\n",
    "\n",
    "        # Append current batch\n",
    "        predictions.append(output_argmax)\n",
    "\n",
    "    # Concatenate to a single tensor\n",
    "    predictions = torch.cat(predictions)\n",
    "\n",
    "    # Map to numpy\n",
    "    predictions = predictions.cpu().detach().numpy()\n",
    "\n",
    "    # Now calculate the metrics\n",
    "    # Use the \"micro\" average - i.e. the calculation is done globally, counting total number of tp, fp and fn for\n",
    "    # each class\n",
    "    precision = metrics.precision_score(y_true=y_test, y_pred=predictions, average='micro')\n",
    "    recall = metrics.recall_score(y_true=y_test, y_pred=predictions, average='micro')\n",
    "    f1 = metrics.f1_score(y_true=y_test, y_pred=predictions, average='micro')\n",
    "    accuracy = metrics.accuracy_score(y_true=y_test, y_pred=predictions)\n",
    "    confusion_matrix = metrics.confusion_matrix(y_true=y_test, y_pred=predictions)\n",
    "\n",
    "    # Return the metrics\n",
    "    return accuracy, precision, recall, f1, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Download datasets through PyTorch if necessary\n",
    "dataset_folder = os.path.join('cached_datasets')\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(dataset_folder, train=True,\n",
    "                                           transform=None, target_transform=None, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(dataset_folder, train=False,\n",
    "                                          transform=None, target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Declaration of models that will be tested on the MNIST and the Fashion MNIST datasets\n",
    "models_mnist = [\n",
    "    DeepSNNModel([28*28, 256, 128, 10]),\n",
    "    DeepSNNModel([28*28, 256, 128, 64, 10]),\n",
    "    DeepSNNModel([28*28, 256, 128, 10], recurrent=True),\n",
    "    DeepSNNModel([28*28, 256, 128, 64, 10], recurrent=True),\n",
    "]\n",
    "\n",
    "# Standardize the MNIST dataset\n",
    "mnist_x_train = np.array(train_dataset.data, dtype=np.float)\n",
    "mnist_x_train = mnist_x_train.reshape(mnist_x_train.shape[0], -1) / 255\n",
    "mnist_x_test = np.array(test_dataset.data, dtype=np.float)\n",
    "mnist_x_test = mnist_x_test.reshape(mnist_x_test.shape[0], -1) / 255\n",
    "\n",
    "mnist_y_train = np.array(train_dataset.targets, dtype=np.int)\n",
    "mnist_y_test = np.array(test_dataset.targets, dtype=np.int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch %i: loss=%.5f\n",
      "Epoch %i: loss=%.5f\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.5964103897348938, 0.2566368494851467]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models_mnist[1]\n",
    "model.train(mnist_x_train, mnist_y_train, 128, num_epochs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Running benchmark on MNIST dataset')\n",
    "\n",
    "# Array for statistics of each model\n",
    "mnist_stats = []\n",
    "for i, model in enumerate(models_mnist):\n",
    "    model.train(mnist_x_train, mnist_y_train, 256, num_epochs=30)\n",
    "    accuracy, precision, recall, f1, confusion_matrix = get_metrics(mnist_x_test, mnist_y_test, 256, model)\n",
    "    stats = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': confusion_matrix\n",
    "    }\n",
    "\n",
    "    print(f'Model {i}: {stats}')\n",
    "    mnist_stats.append(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=0.92969\n",
      "Epoch 2: loss=0.55797\n",
      "Epoch 3: loss=0.47387\n",
      "Epoch 4: loss=0.43576\n",
      "Epoch 5: loss=0.41582\n",
      "Epoch 6: loss=0.41093\n",
      "Epoch 7: loss=0.39499\n",
      "Epoch 8: loss=0.38457\n",
      "Epoch 9: loss=0.37689\n",
      "Epoch 10: loss=0.36526\n",
      "Epoch 11: loss=0.35454\n",
      "Epoch 12: loss=0.34739\n",
      "Epoch 13: loss=0.34859\n",
      "Epoch 14: loss=0.33944\n",
      "Epoch 15: loss=0.33555\n",
      "Epoch 16: loss=0.32322\n",
      "Epoch 17: loss=0.32340\n",
      "Epoch 18: loss=0.31768\n",
      "Epoch 19: loss=0.31241\n",
      "Epoch 20: loss=0.31459\n",
      "Epoch 21: loss=0.31249\n",
      "Epoch 22: loss=0.31338\n",
      "Epoch 23: loss=0.30490\n",
      "Epoch 24: loss=0.29913\n",
      "Epoch 25: loss=0.29269\n",
      "Epoch 26: loss=0.30508\n",
      "Epoch 27: loss=0.30652\n",
      "Epoch 28: loss=0.29266\n",
      "Epoch 29: loss=0.29965\n",
      "Epoch 30: loss=0.28061\n",
      "Model 1, accuracy: 0.86078\n",
      "Epoch 1: loss=1.57793\n",
      "Epoch 2: loss=0.83117\n",
      "Epoch 3: loss=0.53272\n",
      "Epoch 4: loss=0.49433\n",
      "Epoch 5: loss=0.47878\n",
      "Epoch 6: loss=0.46234\n",
      "Epoch 7: loss=0.44445\n",
      "Epoch 8: loss=0.42809\n",
      "Epoch 9: loss=0.43004\n",
      "Epoch 10: loss=0.42607\n",
      "Epoch 11: loss=0.41438\n",
      "Epoch 12: loss=0.40295\n",
      "Epoch 13: loss=0.40429\n",
      "Epoch 14: loss=0.40662\n",
      "Epoch 15: loss=0.40343\n",
      "Epoch 16: loss=0.38395\n",
      "Epoch 17: loss=0.38121\n",
      "Epoch 18: loss=0.39586\n",
      "Epoch 19: loss=0.40166\n",
      "Epoch 20: loss=0.39126\n",
      "Epoch 21: loss=0.38449\n",
      "Epoch 22: loss=0.37023\n",
      "Epoch 23: loss=0.38357\n",
      "Epoch 24: loss=0.39282\n",
      "Epoch 25: loss=0.36885\n",
      "Epoch 26: loss=0.37962\n",
      "Epoch 27: loss=0.37169\n",
      "Epoch 28: loss=0.36205\n",
      "Epoch 29: loss=0.36910\n",
      "Epoch 30: loss=0.36519\n",
      "Model 2, accuracy: 0.84635\n",
      "Epoch 1: loss=1.68388\n",
      "Epoch 2: loss=1.26333\n",
      "Epoch 3: loss=1.17996\n",
      "Epoch 4: loss=0.90601\n",
      "Epoch 5: loss=0.63327\n",
      "Epoch 6: loss=0.58016\n",
      "Epoch 7: loss=0.53985\n",
      "Epoch 8: loss=0.51043\n",
      "Epoch 9: loss=0.47713\n",
      "Epoch 10: loss=0.47467\n",
      "Epoch 11: loss=0.44607\n",
      "Epoch 12: loss=0.43947\n",
      "Epoch 13: loss=0.43269\n",
      "Epoch 14: loss=0.42736\n",
      "Epoch 15: loss=0.41953\n",
      "Epoch 16: loss=0.41448\n",
      "Epoch 17: loss=0.40578\n",
      "Epoch 18: loss=0.40143\n",
      "Epoch 19: loss=0.40499\n",
      "Epoch 20: loss=0.38766\n",
      "Epoch 21: loss=0.38542\n",
      "Epoch 22: loss=0.38404\n",
      "Epoch 23: loss=0.36950\n",
      "Epoch 24: loss=0.38502\n",
      "Epoch 25: loss=0.36887\n",
      "Epoch 26: loss=0.37326\n",
      "Epoch 27: loss=0.37087\n",
      "Epoch 28: loss=0.36370\n",
      "Epoch 29: loss=0.36864\n",
      "Epoch 30: loss=0.39352\n",
      "Model 3, accuracy: 0.80929\n",
      "Epoch 1: loss=1.85568\n",
      "Epoch 2: loss=1.08235\n",
      "Epoch 3: loss=0.90405\n",
      "Epoch 4: loss=0.80624\n",
      "Epoch 5: loss=0.79858\n",
      "Epoch 6: loss=0.78962\n",
      "Epoch 7: loss=0.78901\n",
      "Epoch 8: loss=0.80122\n",
      "Epoch 9: loss=0.77443\n",
      "Epoch 10: loss=0.84846\n",
      "Epoch 11: loss=0.78881\n",
      "Epoch 12: loss=0.80098\n",
      "Epoch 13: loss=0.78216\n",
      "Epoch 14: loss=0.79123\n",
      "Epoch 15: loss=0.76397\n",
      "Epoch 16: loss=0.70147\n",
      "Epoch 17: loss=0.74243\n",
      "Epoch 18: loss=0.73036\n",
      "Epoch 19: loss=0.75287\n",
      "Epoch 20: loss=0.80149\n",
      "Epoch 21: loss=0.78952\n",
      "Epoch 22: loss=0.83583\n",
      "Epoch 23: loss=0.76245\n",
      "Epoch 24: loss=0.78097\n",
      "Epoch 25: loss=0.87556\n",
      "Epoch 26: loss=0.85582\n",
      "Epoch 27: loss=0.84490\n",
      "Epoch 28: loss=0.79332\n",
      "Epoch 29: loss=0.83105\n",
      "Epoch 30: loss=0.86509\n",
      "Model 4, accuracy: 0.69291\n"
     ]
    }
   ],
   "source": [
    "# Fashion MNIST\n",
    "train_dataset = torchvision.datasets.FashionMNIST(dataset_folder, train=True,\n",
    "                                           transform=None, target_transform=None, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(dataset_folder, train=False,\n",
    "                                          transform=None, target_transform=None, download=True)\n",
    "# Create the same models for the Fashion MNIST dataset\n",
    "models_fashion_mnist = [\n",
    "    DeepSNNModel([28*28, 256, 128, 10]),\n",
    "    DeepSNNModel([28*28, 256, 128, 64, 10]),\n",
    "    DeepSNNModel([28*28, 256, 128, 10], recurrent=True),\n",
    "    DeepSNNModel([28*28, 256, 128, 64, 10], recurrent=True),\n",
    "]\n",
    "# Standardize the data\n",
    "fmnist_x_train = np.array(train_dataset.data, dtype=np.float)\n",
    "fmnist_x_train = fmnist_x_train.reshape(fmnist_x_train.shape[0], -1) / 255\n",
    "fmnist_x_test = np.array(test_dataset.data, dtype=np.float)\n",
    "fmnist_x_test = fmnist_x_test.reshape(fmnist_x_test.shape[0], -1) / 255\n",
    "\n",
    "fmnist_y_train = np.array(train_dataset.targets, dtype=np.int)\n",
    "fmnist_y_test = np.array(test_dataset.targets, dtype=np.int)\n",
    "\n",
    "fashion_mnist_stats = []\n",
    "i = 1\n",
    "for i, model in enumerate(models_fashion_mnist):\n",
    "    model.train(mnist_x_train, mnist_y_train, 256, num_epochs=30) # train the model\n",
    "\n",
    "    # Get metrics\n",
    "    accuracy, precision, recall, f1, confusion_matrix = get_metrics(mnist_x_test, mnist_y_test, 256, model)\n",
    "\n",
    "    # Create dictionary for later use\n",
    "    stats = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': confusion_matrix\n",
    "    }\n",
    "\n",
    "    # Print and save the stats\n",
    "    print(f'Model {i}: {stats}')\n",
    "    fashion_mnist_stats.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}