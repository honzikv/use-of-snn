{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device('cuda')\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "root = os.path.expanduser('~/data/datasets/torch/mnist')\n",
    "train_dataset = torchvision.datasets.MNIST(root, train=True, transform=None, target_transform=None, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root, train=False, transform=None, target_transform=None, download=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "# flatten and normalize\n",
    "x_train = np.array(train_dataset.data, dtype=np.float)\n",
    "x_train = x_train.reshape(x_train.shape[0], -1) / 255\n",
    "\n",
    "x_test = np.array(test_dataset.data, dtype=np.float)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1) / 255\n",
    "\n",
    "y_train = np.array(train_dataset.targets, dtype=np.long)\n",
    "y_test = np.array(test_dataset.targets, dtype=np.long)\n",
    "\n",
    "del train_dataset, test_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "data": {
      "text/plain": "(-0.5, 27.5, 27.5, -0.5)"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[15].reshape(28, 28), cmap=plt.cm.gray_r)\n",
    "plt.axis('off')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_inputs, num_hidden, num_outputs = 28 * 28, 100, 10\n",
    "\n",
    "time_step, num_steps = 1e-3, 100\n",
    "\n",
    "batch_size = 256\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "def current_to_firing_time(x, tau=20, firing_threshold=0.2, time_max = 1.0, epsilon=1e-7):\n",
    "    \"\"\"\n",
    "\n",
    "    :param x: data\n",
    "    :param tau: time constant of the membrane in LIF neuron model\n",
    "    :param firing_threshold: firing threshold value\n",
    "    :param time_max: maximum time to be returned\n",
    "    :param epsilon: generic epsilon > 0\n",
    "    :return: time to first spike for each \"current\" x\n",
    "    \"\"\"\n",
    "    index = x < firing_threshold\n",
    "    x = np.clip(x, firing_threshold + epsilon, 1e9)\n",
    "    times_for_first_spike = tau * np.log(x / (x - firing_threshold))\n",
    "    times_for_first_spike[index] = time_max\n",
    "    return times_for_first_spike\n",
    "\n",
    "def sparse_data_generator(features, labels, batch_size, nb_steps, nb_units, shuffle=True):\n",
    "    \"\"\"\n",
    "    Generates spiking network input from standard analog input\n",
    "    :param features: features - num_samples x given_event x (time, neuron)\n",
    "    :param labels: labels\n",
    "    \"\"\"\n",
    "\n",
    "    labels = np.array(labels, dtype=np.long)\n",
    "    num_of_batches = len(features) // batch_size\n",
    "    sample_index = np.arange(len(features))\n",
    "\n",
    "    tau_eff = 20e-3 / time_step\n",
    "\n",
    "    firing_times = current_to_firing_time(features, tau=tau_eff, time_max=nb_steps)\n",
    "    firing_times = np.array(firing_times, dtype=np.long)\n",
    "\n",
    "    unit_numbers = np.arange(nb_units)\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "\n",
    "    counter, total_batch_count = 0, 0\n",
    "    while counter < num_of_batches:\n",
    "        batch_index = sample_index[batch_size*counter : batch_size*(counter+1)]\n",
    "\n",
    "        data = [ [] for _ in range(3)]\n",
    "\n",
    "        for bc, idx in enumerate(batch_index):\n",
    "            c = firing_times[idx] < nb_steps\n",
    "            times, units = firing_times[idx][c], unit_numbers[c]\n",
    "\n",
    "            batch = [bc for _ in range(len(times))]\n",
    "            data[0].extend(batch)\n",
    "            data[1].extend(times)\n",
    "            data[2].extend(units)\n",
    "\n",
    "        i = torch.LongTensor(data).to(device)\n",
    "        v = torch.FloatTensor(np.ones(len(data[0]))).to(device)\n",
    "\n",
    "        x_batch = torch.sparse.FloatTensor(i, v, torch.Size([batch_size, nb_steps, nb_units])).to(device)\n",
    "        y_batch = torch.tensor(labels[batch_index], device=device, dtype=torch.long) # chybel dtype\n",
    "\n",
    "        yield x_batch.to(device=device), y_batch.to(device=device)\n",
    "\n",
    "        counter += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "# Spiking network setup\n",
    "\n",
    "tau_membrane, tau_synapse = 10e-3, 5e-3\n",
    "alpha, beta = float(np.exp(-time_step/tau_synapse)), float(np.exp(-time_step/tau_membrane))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-150-110c50862c3a>:6: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  torch.nn.init.normal(w2, mean=0.0, std=weight_scale / np.sqrt(num_hidden))\n"
     ]
    }
   ],
   "source": [
    "weight_scale = 7 * (1.0 - beta)\n",
    "\n",
    "w1 = torch.empty((num_inputs, num_hidden), device=device, dtype=dtype, requires_grad=True)\n",
    "w2 = torch.empty((num_hidden, num_outputs), device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "torch.nn.init.normal(w2, mean=0.0, std=weight_scale / np.sqrt(num_hidden))\n",
    "\n",
    "print('initialized')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "class SurrGradSpike(torch.autograd.Function):\n",
    "\n",
    "    scale = 100.0\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we compute a step function of the input Tensor\n",
    "        and return it. ctx is a context object that we use to stash information which\n",
    "        we need to later backpropagate our error signals. To achieve this we use the\n",
    "        ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        out = torch.zeros_like(input)\n",
    "        out[input > 0] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor we need to compute the\n",
    "        surrogate gradient of the loss with respect to the input.\n",
    "        Here we use the normalized negative part of a fast sigmoid\n",
    "        as this was done in Zenke & Ganguli (2018).\n",
    "        \"\"\"\n",
    "        input = ctx.saved_tensors # ,\n",
    "        grad_input = grad_output.clone()\n",
    "        grad = grad_input / (SurrGradSpike.scale * torch.abs(input) + 1.0) ** 2\n",
    "        return grad\n",
    "\n",
    "spike_fn = SurrGradSpike.apply"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "def run_snn(inputs):\n",
    "    h1 = torch.einsum('abc,cd->abd', (inputs, w1))\n",
    "    synapse = torch.zeros((batch_size, num_hidden), device=device, dtype=dtype)\n",
    "    membrane = torch.zeros((batch_size, num_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    mem_recordings = [membrane]\n",
    "    spike_recordings = [membrane]\n",
    "\n",
    "    for dt in range(num_steps):\n",
    "        membrane_threshold = membrane - 1.0\n",
    "        out = spike_fn(membrane_threshold)\n",
    "        rst = torch.zeros_like(membrane)\n",
    "        c = (membrane_threshold > 0)\n",
    "        rst[c] = torch.ones_like(membrane)[c]\n",
    "\n",
    "        new_synapse = alpha * synapse + h1[:, dt]\n",
    "        new_membrane = beta * membrane - rst\n",
    "\n",
    "        membrane, synapse = new_membrane, new_synapse\n",
    "        mem_recordings.append(membrane)\n",
    "        spike_recordings.append(out)\n",
    "\n",
    "    mem_recordings = torch.stack(mem_recordings, dim=1)\n",
    "    spike_recordings = torch.stack(spike_recordings, dim=1)\n",
    "\n",
    "    h2 = torch.einsum('abc,cd->abd', (spike_recordings, w2))\n",
    "    flt = torch.zeros((batch_size, num_outputs), device=device, dtype=dtype)\n",
    "    out = torch.zeros((batch_size, num_outputs), device=device, dtype=dtype)\n",
    "    out_recordings = [out]\n",
    "\n",
    "    for dt in range(num_steps):\n",
    "        new_flt = alpha * flt + h2[:, dt]\n",
    "        new_out = beta * out + flt\n",
    "\n",
    "        flt, out = new_flt, new_out\n",
    "        out_recordings.append(out)\n",
    "\n",
    "    out_recordings = torch.stack(out_recordings, dim=1) # output layer results\n",
    "    other_recordings = [mem_recordings, spike_recordings] # spikes and membrane recordings for visualization\n",
    "\n",
    "    return out_recordings, other_recordings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "def train(x_data, y_data, lr=2e-3, num_epochs=10):\n",
    "    params = [w1, w2]\n",
    "    optimizer = torch.optim.Adam(params, lr=lr, betas=(0.9,0.999))\n",
    "\n",
    "    log_softmax_fn = nn.LogSoftmax(dim=1)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "\n",
    "    loss_hist = []\n",
    "    for epoch in range(num_epochs):\n",
    "        local_loss = []\n",
    "        for x_local, y_local in sparse_data_generator(features=x_data, labels=y_data, batch_size=batch_size,\n",
    "                                                      nb_steps=num_steps, nb_units=num_inputs, time_step=time_step):\n",
    "            output, _ = run_snn(inputs=x_local.to_dense())\n",
    "            m, _ = torch.max(output, 1)\n",
    "            log_p_y = log_softmax_fn(m)\n",
    "            loss_val = loss_fn(log_p_y, y_local)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "            local_loss.append(loss_val.item())\n",
    "\n",
    "        mean_loss = np.mean(local_loss)\n",
    "        print(\"Epoch %i: loss=%.5f\"%(epoch+1,mean_loss))\n",
    "        loss_hist.append(mean_loss)\n",
    "\n",
    "def get_accuracy(x_data, y_data):\n",
    "    accs = []\n",
    "    for x_local, y_local in sparse_data_generator(x_data, y_data, batch_size, num_steps, num_inputs, False, time_step):\n",
    "        output = run_snn(x_local.to_dense())\n",
    "        m, _ = torch.max(output, 1)\n",
    "        _, am = torch.max(m, 1)\n",
    "        accs.append(np.mean((y_local == am).detach().cpu().numpy()))\n",
    "    return np.mean(accs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=2.30258\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-154-1d1ba7012011>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mloss_hist\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m2e-4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m30\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-153-7e1e9d57a660>\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(x_data, y_data, lr, num_epochs)\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m             \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 19\u001B[1;33m             \u001B[0mloss_val\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     20\u001B[0m             \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m             \u001B[0mlocal_loss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss_val\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\data-science\\lib\\site-packages\\torch\\tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph)\u001B[0m\n\u001B[0;32m    219\u001B[0m                 \u001B[0mretain_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    220\u001B[0m                 create_graph=create_graph)\n\u001B[1;32m--> 221\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    222\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    223\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\data-science\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001B[0m\n\u001B[0;32m    128\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    129\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 130\u001B[1;33m     Variable._execution_engine.run_backward(\n\u001B[0m\u001B[0;32m    131\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    132\u001B[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "loss_hist = train(x_train, y_train, lr=2e-4, num_epochs=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3.3,2),dpi=150)\n",
    "plt.plot(loss_hist)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "sns.despine()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Training accuracy: %.3f\"%(get_accuracy(x_train,y_train)))\n",
    "print(\"Test accuracy: %.3f\"%(get_accuracy(x_test,y_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-9c9070f4",
   "language": "python",
   "display_name": "PyCharm (use-of-snn)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}